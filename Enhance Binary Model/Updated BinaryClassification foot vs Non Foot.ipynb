{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing A01...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 32.8s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A02...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 43.6s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A03...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 51.5s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A05...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686119  =      0.000 ...  2744.476 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 47.6s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A06...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 678979  =      0.000 ...  2715.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 49.9s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A07...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 39.7s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A08...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675269  =      0.000 ...  2701.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 45.4s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A09...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 88.2s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Features shape: (2304, 22, 876)\n",
      "Labels shape: (2304,)\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, SeparableConv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- Data Loading and Preprocessing ----------------\n",
    "\n",
    "# Base path for EEG data files\n",
    "base_path = r'C:\\\\Users\\\\karan\\Downloads\\\\EEG Data\\\\Data'\n",
    "subjects = [f'A0{i}' for i in range(1, 10) if i != 4]\n",
    "event_ids = [7, 8, 9, 10]  # Event IDs for motor imagery tasks: Right Hand, Left Hand, Feet, Tongue\n",
    "\n",
    "# Initialize lists to hold data\n",
    "all_features, all_labels = [], []\n",
    "\n",
    "# Loop through each subject\n",
    "for subject in subjects:\n",
    "    file_path = f'{base_path}\\\\{subject}T.gdf'\n",
    "    print(f\"Processing {subject}...\")\n",
    "\n",
    "    # Load raw EEG data\n",
    "    raw = mne.io.read_raw_gdf(file_path, preload=True)\n",
    "    raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])  # Drop EOG channels\n",
    "    raw.set_eeg_reference()  # Set average reference\n",
    "    raw.filter(8., 30., fir_design='firwin', verbose=False)  # Bandpass filter (8–30 Hz)\n",
    "\n",
    "    # Apply ICA for artifact removal\n",
    "    ica = mne.preprocessing.ICA(n_components=15, random_state=97, max_iter=800)\n",
    "    ica.fit(raw)\n",
    "    raw = ica.apply(raw)  # Remove artifacts\n",
    "\n",
    "    # Extract events and epochs\n",
    "    events, _ = mne.events_from_annotations(raw)\n",
    "    epochs = mne.Epochs(\n",
    "        raw, events, event_id=event_ids, tmin=0.5, tmax=4.0, baseline=(0.5, 1.0), preload=True\n",
    "    )\n",
    "\n",
    "    # Append features and labels\n",
    "    all_features.append(epochs.get_data())  # Shape: (n_epochs, n_channels, n_times)\n",
    "    all_labels.append(epochs.events[:, -1])  # Event IDs (labels)\n",
    "\n",
    "# Combine data from all subjects\n",
    "features = np.concatenate(all_features, axis=0)\n",
    "labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (5875, 22, 876, 1)\n",
      "Testing set shape: (1037, 22, 876, 1)\n",
      "Training labels shape: (5875,)\n",
      "Testing labels shape: (1037,)\n",
      "Epoch 1/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 102ms/step - accuracy: 0.5095 - loss: 2.1383 - val_accuracy: 0.5295 - val_loss: 1.6343 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 101ms/step - accuracy: 0.5837 - loss: 1.3092 - val_accuracy: 0.5329 - val_loss: 1.4937 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 94ms/step - accuracy: 0.6647 - loss: 1.0593 - val_accuracy: 0.6667 - val_loss: 1.0625 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 87ms/step - accuracy: 0.7102 - loss: 1.0177 - val_accuracy: 0.7234 - val_loss: 1.0282 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 90ms/step - accuracy: 0.7662 - loss: 0.9616 - val_accuracy: 0.8322 - val_loss: 0.9012 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 85ms/step - accuracy: 0.8085 - loss: 0.9420 - val_accuracy: 0.8594 - val_loss: 0.8785 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.8404 - loss: 0.9070 - val_accuracy: 0.8832 - val_loss: 0.8563 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.8401 - loss: 0.9203 - val_accuracy: 0.9014 - val_loss: 0.8374 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.8514 - loss: 0.9076 - val_accuracy: 0.9014 - val_loss: 0.8341 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.8564 - loss: 0.9220 - val_accuracy: 0.9263 - val_loss: 0.8070 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.8616 - loss: 0.9130 - val_accuracy: 0.9093 - val_loss: 0.8308 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 79ms/step - accuracy: 0.8532 - loss: 1.0128 - val_accuracy: 0.9184 - val_loss: 0.8846 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.8676 - loss: 0.9596 - val_accuracy: 0.9422 - val_loss: 0.8217 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.8685 - loss: 0.9306 - val_accuracy: 0.9320 - val_loss: 0.8291 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.8798 - loss: 0.9006 - val_accuracy: 0.9308 - val_loss: 0.7869 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.8916 - loss: 0.8396 - val_accuracy: 0.9478 - val_loss: 0.7727 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.8989 - loss: 0.8291 - val_accuracy: 0.9342 - val_loss: 0.7534 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.9053 - loss: 0.8191 - val_accuracy: 0.9422 - val_loss: 0.7788 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.8587 - loss: 0.9764 - val_accuracy: 0.9240 - val_loss: 0.8728 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.8950 - loss: 0.9183 - val_accuracy: 0.9603 - val_loss: 0.7848 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9047 - loss: 0.8655 - val_accuracy: 0.9274 - val_loss: 0.8201 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9067 - loss: 0.8267\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9067 - loss: 0.8266 - val_accuracy: 0.9331 - val_loss: 0.7697 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - accuracy: 0.9227 - loss: 0.7622 - val_accuracy: 0.9773 - val_loss: 0.6024 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.9358 - loss: 0.6744 - val_accuracy: 0.9762 - val_loss: 0.5524 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9424 - loss: 0.5976 - val_accuracy: 0.9546 - val_loss: 0.5594 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9495 - loss: 0.5475 - val_accuracy: 0.9626 - val_loss: 0.4976 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9567 - loss: 0.4979 - val_accuracy: 0.9580 - val_loss: 0.4785 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.9261 - loss: 0.5693 - val_accuracy: 0.9683 - val_loss: 0.4844 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9486 - loss: 0.5131 - val_accuracy: 0.9683 - val_loss: 0.4676 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.9463 - loss: 0.5149 - val_accuracy: 0.9739 - val_loss: 0.4523 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9163 - loss: 0.5927 - val_accuracy: 0.9615 - val_loss: 0.5041 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9408 - loss: 0.5517 - val_accuracy: 0.9739 - val_loss: 0.4763 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9357 - loss: 0.5634 - val_accuracy: 0.9739 - val_loss: 0.5007 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9456 - loss: 0.5628 - val_accuracy: 0.9615 - val_loss: 0.5179 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9459 - loss: 0.5308\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9458 - loss: 0.5308 - val_accuracy: 0.9739 - val_loss: 0.4664 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9583 - loss: 0.5017 - val_accuracy: 0.9785 - val_loss: 0.4371 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.9606 - loss: 0.4617 - val_accuracy: 0.9773 - val_loss: 0.4204 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9643 - loss: 0.4332 - val_accuracy: 0.9751 - val_loss: 0.4004 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9714 - loss: 0.3939 - val_accuracy: 0.9841 - val_loss: 0.3633 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.9724 - loss: 0.3788 - val_accuracy: 0.9807 - val_loss: 0.3534 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - accuracy: 0.9690 - loss: 0.3642 - val_accuracy: 0.9762 - val_loss: 0.3517 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 83ms/step - accuracy: 0.9715 - loss: 0.3425 - val_accuracy: 0.9785 - val_loss: 0.3297 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9685 - loss: 0.3320 - val_accuracy: 0.9807 - val_loss: 0.3122 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9705 - loss: 0.3250 - val_accuracy: 0.9773 - val_loss: 0.3129 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9693 - loss: 0.3293 - val_accuracy: 0.9785 - val_loss: 0.3082 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9734 - loss: 0.3143 - val_accuracy: 0.9773 - val_loss: 0.3031 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9715 - loss: 0.3071 - val_accuracy: 0.9796 - val_loss: 0.2903 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 84ms/step - accuracy: 0.9737 - loss: 0.2985 - val_accuracy: 0.9751 - val_loss: 0.3008 - learning_rate: 2.5000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 84ms/step - accuracy: 0.9759 - loss: 0.2923 - val_accuracy: 0.9807 - val_loss: 0.2919 - learning_rate: 2.5000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 88ms/step - accuracy: 0.9703 - loss: 0.3018 - val_accuracy: 0.9807 - val_loss: 0.2779 - learning_rate: 2.5000e-04\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Test Accuracy: 97.30%\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "Confusion Matrix:\n",
      " [[494  28]\n",
      " [  0 515]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.97       522\n",
      "         1.0       0.95      1.00      0.97       515\n",
      "\n",
      "    accuracy                           0.97      1037\n",
      "   macro avg       0.97      0.97      0.97      1037\n",
      "weighted avg       0.97      0.97      0.97      1037\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABz3UlEQVR4nO3dd1QU198G8GcpS+8gRRSwIHYQYo1dUTAaW8ASey+xoDEajb0lNjT2HmPDHo0Ve4/dGDWxoaKCBRWQzu59/+Blf66AsrgwlOdzzh7du1OeHdidL3fuzMiEEAJEREREhYSO1AGIiIiItInFDRERERUqLG6IiIioUGFxQ0RERIUKixsiIiIqVFjcEBERUaHC4oaIiIgKFRY3REREVKiwuCEiIqJChcUN5cjatWshk8lUDz09PTg6OqJDhw64e/eu1PEAAK6urujevbvUMTKIi4vDzJkz4eXlBVNTU5iYmMDT0xPTp09HXFyc1PGybfr06di1a1eG9uPHj0Mmk+H48eN5nindgwcPMHjwYLi7u8PIyAjGxsaoWLEixo0bh6dPn6qma9CgASpVqiRZzs+xceNGBAcH59ryc/L5OXv2LCZOnIi3b99meK1BgwZo0KCBVrKla9y4Mfr37696nv67l/7Q1dWFnZ0dWrZsiUuXLmW6DCEENm7ciEaNGsHKygoGBgYoVaoUBg0ahPDw8CzXvWfPHrRs2RL29vaQy+WwtrZG48aNsWHDBqSkpAAA3rx5A0tLy0w/J5TLBFEOrFmzRgAQa9asEefOnRPHjh0TU6dOFUZGRqJYsWLi9evXUkcUV65cEffu3ZM6hprIyEhRqVIlYWRkJH744Qdx6NAhcejQITF69GhhZGQkKlWqJCIjI6WOmS0mJiaiW7duGdqjo6PFuXPnRHR0dN6HEkLs2bNHmJiYCBcXFzFr1ixx+PBhceTIEREcHCyqVKkiPD09VdPWr19fVKxYUZKcn6tFixbCxcUl15afk8/PrFmzBAARFhaW4bWbN2+KmzdvaimdELt27RIGBgbiyZMnqrZjx44JAGL69Oni3Llz4uTJk2L+/PnC2tpaGBsbizt37qgtQ6FQiMDAQAFAdOzYUezatUscO3ZMzJ8/Xzg7OwtLS0tx+vRptXmUSqXo3r27ACD8/f3F+vXrxYkTJ8Tu3bvF8OHDhbm5uQgODlZNP3HiRFGmTBmRlJSktfdOn8bihnIkvbi5ePGiWvukSZMEALF69WqJkkkrNTVVJCYmZvm6r6+v0NPTE6dOncrw2qlTp4Senp5o1qxZbkbM1KdyZyar4kZKDx48ECYmJsLLy0u8ffs2w+tKpVJs375d9TwvihulUini4+O1vtzcKm4+J+vHihttq169uujQoYNaW3pxs3XrVrX23377TQAQ48ePV2ufPn26ACBmzpyZYfmRkZHCxcVF2Nvbizdv3qjaf/75ZwFATJo0KdNcERERap/vyMhIoaenJzZs2KDpW6TPwOKGciSr4mbv3r0CgJgxY4Za+8WLF0XLli2FlZWVMDAwEJ6eniIkJCTDcp88eSL69OkjnJ2dhb6+vnB0dBTt2rVT682Ijo4WI0aMEK6urkJfX184OTmJoUOHinfv3qkty8XFRbXzffHihdDX1xfjxo3LsM7bt28LAGL+/PmqtoiICNG3b19RvHhxoa+vL1xdXcXEiRNFSkqKapqwsDABQPz8889iypQpwtXVVejq6or9+/dnus0uXrwoAIh+/fplsVWF6Nu3rwAgLl26pGoDIAYNGiSWLl0qypYtK+RyuShfvrzYtGlThvk/N3dCQoIICgoSVatWFebm5sLKykrUrFlT7Nq1S209ADI86tevL4T43w7m2LFjqum7desmTExMxN27d4Wfn58wMTERzs7OIigoKENRFR4eLtq1aydMTU2FhYWF6NSpk7hw4YKqp/BjBg8eLACIc+fOfXS6dOnFzYULF8SXX34pjIyMhJubm5gxY4ZQKBSq6bK7XdK3zaBBg8SSJUuEh4eH0NfXF0uWLBFCpP0VX716dWFlZSXMzMyEl5eXWLlypVAqlRmWs2HDBlGzZk1hYmIiTExMRNWqVcXKlStVuTP7GaRLSkoSU6ZMEeXKlRNyuVzY2tqK7t27ixcvXqitw8XFRbRo0UJs375deHp6CgMDA/HDDz+oXnu/eFUoFGLKlCnC3d1dGBoaCgsLC1G5cmVVL8WECRMyzZT+e1C/fn3V70i6xMREMWnSJOHh4SEMDAyEtbW1aNCggThz5sxHf25XrlwRAMTevXvV2rMqbm7evJnhs5eUlCSsrKxE+fLlM93+QgixceNGAUDMnj1bCCFEcnKysLa2Fh4eHlnOkxk/Pz9Rt27dbE9Pn08vl452UREVFhYGAHB3d1e1HTt2DM2bN0eNGjWwdOlSWFhYYPPmzQgMDER8fLzquP7Tp0/xxRdfICUlBT/++COqVKmCqKgoHDx4EG/evIG9vT3i4+NRv359PHnyRDXNzZs3MX78eNy4cQOHDx+GTCbLkMvOzg5fffUVfvvtN0yaNAk6Ov8bbrZmzRrI5XJ07twZABAZGYnq1atDR0cH48ePR+nSpXHu3DlMnToVDx8+xJo1a9SWvWDBAri7u2P27NkwNzdH2bJlM902oaGhAIDWrVtnuf1at26N5cuXIzQ0FN7e3qr23bt349ixY5g8eTJMTEywePFidOzYEXp6emjfvr3WciclJeH169cYOXIkihcvjuTkZBw+fBht27bFmjVr0LVrVwDAuXPn0KhRIzRs2BA//fQTAMDc3DzL9wUAKSkpaNWqFXr16oURI0bg5MmTmDJlCiwsLDB+/HgAaeORGjZsiNevX+Pnn39GmTJlcODAAQQGBn502ekOHToEe3t71KxZM1vTp2+3zp07Y8SIEZgwYQJ27tyJMWPGwMnJSfV+s7td0u3atQunTp3C+PHj4eDggGLFigEAHj58iH79+qFkyZIAgPPnz+O7777D06dPVdsAAMaPH48pU6agbdu2GDFiBCwsLPDPP//g0aNHAIDFixejb9++uH//Pnbu3Km2bqVSia+//hqnTp3CqFGjULt2bTx69AgTJkxAgwYNcOnSJRgZGammv3LlCm7fvo1x48bBzc0NJiYmmW6nX375BRMnTsS4ceNQr149pKSk4N9//1WNr+nduzdev36NX3/9FTt27ICjoyMAoEKFCpkuLzU1FX5+fjh16hSGDRuGRo0aITU1FefPn8fjx49Ru3btLH9mf/75J3R1dVGvXr0sp3lfZt9Lly9fxps3b9C3b99MvzMAoGXLltDR0UFoaChGjBiBS5cu4fXr1+jTp0+W82SmQYMGGDNmDN6+fQtLS8tsz0efQerqigqm9J6b8+fPi5SUFBEbGysOHDggHBwcRL169dR6Cjw8PISXl5damxBCfPXVV8LR0VH1F3LPnj2Fvr6+uHXrVpbrnTFjhtDR0cnQY7Rt2zYBQOzbt0/V9uFfnrt37xYAxKFDh1RtqampwsnJSbRr107V1q9fP2FqaioePXqkto7Zs2cLAKpxA+k9IKVLlxbJycmf2mSif//+AoD4999/s5wmvRdpwIABqjYAwsjISK33KjU1VXh4eIgyZcrkau7U1FSRkpIievXqJby8vNRey+qwVFY9NwDEli1b1Kb19/cX5cqVUz1ftGiRAJCh96tfv37Z6rkxNDQUNWvW/Og070vvAfnrr7/U2itUqPDRw4Mf2y4AhIWFxSfHnSkUCpGSkiImT54sbGxsVD0BDx48ELq6uqJz584fnT+rw1KbNm0SANQOvwnxv57DxYsXq9pcXFyErq6u+O+//zIs58PPz1dffaU2XikzHzss9WHPzbp16wQAsWLFio8uMzN+fn7Cw8MjQ3v6715ISIhISUkR8fHx4syZM6JcuXKiQoUKaoeXNm/eLACIpUuXfnRd9vb2onz58hrN86HQ0NBMf68p9/BsKfosNWvWhL6+PszMzNC8eXNYWVnhjz/+gJ5eWqfgvXv38O+//6p6RVJTU1UPf39/RERE4L///gMA7N+/Hw0bNkT58uWzXN+ff/6JSpUqwdPTU21ZzZo1++QZOn5+fnBwcFDrwTh48CCePXuGnj17qq2jYcOGcHJyUluHn58fAODEiRNqy23VqhX09fU123BZEEIAQIa/Chs3bgx7e3vVc11dXQQGBuLevXt48uSJVnNv3boVderUgampKfT09KCvr49Vq1bh9u3bn/XeZDIZWrZsqdZWpUoVVW9Eesb036X3dezY8bPW/TEODg6oXr36R3MBmm2X9DNvPnT06FE0adIEFhYW0NXVhb6+PsaPH4+oqCi8ePECQFoPn0KhwKBBg3L0fv78809YWlqiZcuWar8Hnp6ecHBwyPAZqVKlilqPRlaqV6+O69evY+DAgTh48CBiYmJylC/d/v37YWhoqPbZy65nz56pesMyExgYCH19fRgbG6NOnTqIiYnB3r17c9RrIoTQqJcmM+lZ3z9Tj3IXixv6LOvWrcPFixdx9OhR9OvXD7dv31bbET1//hwAMHLkSOjr66s9Bg4cCAB49eoVAODly5dwdnb+6PqeP3+Ov//+O8OyzMzMIIRQLSszenp66NKlC3bu3KnqSl+7di0cHR3RrFkztXXs2bMnwzoqVqyoljddevf7p6QfikjvIs/Mw4cPAQAlSpRQa3dwcMgwbXpbVFSU1nLv2LEDAQEBKF68ONavX49z587h4sWL6NmzJxITE7P1PrNibGwMQ0NDtTYDAwO15UZFRakVcekya8tMyZIlP7p9M2NjY5OhzcDAAAkJCarnmm6XzLbthQsX4OvrCwBYsWIFzpw5g4sXL2Ls2LEAoFrfy5cvAeCTn4WsPH/+HG/fvoVcLs/wuxAZGZnj398xY8Zg9uzZOH/+PPz8/GBjY4PGjRtneYr1p7x8+RJOTk5qh4izKyEhIcPv0vt+/vlnXLx4ESdOnMDYsWPx/PlztG7dGklJSappsvN5jIuLw6tXr1Sfx+zMk5n0rO//TlHu4pgb+izly5eHj48PAKBhw4ZQKBRYuXIltm3bhvbt28PW1hZA2hdj27ZtM11GuXLlAKSNi0nvhciKra0tjIyMsHr16ixf/5gePXpg1qxZqjE/u3fvxrBhw6Crq6u2jCpVqmDatGmZLsPJyUnteXb/qmvatCl+/PFH7Nq1K0PPRLr062E0bdpUrT0yMjLDtOlt6TtnbeRev3493NzcEBISovb6+zuF3GRjY4MLFy5kaM/s/WemWbNm+PXXX3H+/HmNxt18iqbbJbNtu3nzZujr6+PPP/9U2zF/eA0UOzs7AMCTJ08yFLnZYWtrCxsbGxw4cCDT183MzD6ZNTN6enoICgpCUFAQ3r59i8OHD+PHH39Es2bNEB4eDmNjY41y2tnZ4fTp01AqlRoXOLa2tnj9+nWWr5cqVUr1vVSvXj0YGRlh3Lhx+PXXXzFy5EgAgLe3N6ysrLB7927MmDEj0+2we/duKJVK1efRx8cH1tbW+OOPP7KcJzPpWT/1/UTaw54b0qpffvkFVlZWGD9+PJRKJcqVK4eyZcvi+vXr8PHxyfSR/mXr5+eHY8eOqQ5TZearr77C/fv3YWNjk+myXF1dP5qvfPnyqFGjBtasWYONGzciKSkJPXr0yLCOf/75B6VLl850HR8WCdnl4+MDX19frFq1CmfOnMnw+unTp7F69Wo0b95cbTAxABw5ckTVCwYACoUCISEhKF26tOovfG3klslkkMvlal/akZGR+OOPPzJM+2HvhjbUr18fsbGx2L9/v1r75s2bszX/8OHDYWJigoEDByI6OjrD60KIDANws0OT7fKxZejp6akV0gkJCfj999/VpvP19YWuri6WLFny0eVltf2/+uorREVFQaFQZPp7kP7HxOewtLRE+/btMWjQILx+/VrV42hgYKB6X5/i5+eHxMRErF27VuP1e3h44MGDB9meftSoUShTpgxmzpyJ2NhYAIBcLsf333+P27dvY9asWRnmefHiBcaMGQN7e3v07t0bAKCvr48ffvgB//77L6ZMmZLpul68eJHh852eNavB1aR97LkhrbKyssKYMWMwatQobNy4Ed9++y2WLVsGPz8/NGvWDN27d0fx4sXx+vVr3L59G1euXMHWrVsBAJMnT8b+/ftRr149/Pjjj6hcuTLevn2LAwcOICgoCB4eHhg2bBi2b9+OevXqYfjw4ahSpQqUSiUeP36MQ4cOYcSIEahRo8ZHM/bs2RP9+vXDs2fPULt27Qxf9pMnT0ZoaChq166NIUOGoFy5ckhMTMTDhw+xb98+LF26NMeHDNatW4cmTZrA19cXQ4YMQePGjQGkjcWYP38+PDw8Mv2yt7W1RaNGjfDTTz+pzpb6999/1Xb62sj91VdfYceOHRg4cCDat2+P8PBwTJkyBY6OjhmuPF25cmUcP34ce/bsgaOjI8zMzD57x9mtWzfMmzcP3377LaZOnYoyZcpg//79OHjwIAB88i98Nzc3Va+cp6cnBg8eDC8vLwDArVu3sHr1aggh0KZNG41yabJdstKiRQvMnTsXnTp1Qt++fREVFYXZs2erCoJ0rq6u+PHHHzFlyhQkJCSgY8eOsLCwwK1bt/Dq1StMmjQJQNr237FjB5YsWQJvb2/o6OjAx8cHHTp0wIYNG+Dv74+hQ4eievXq0NfXx5MnT3Ds2DF8/fXXGr9/IO3MoUqVKsHHxwd2dnZ49OgRgoOD4eLiojpDsHLlygCA+fPno1u3btDX10e5cuUy9BYBaeOo1qxZg/79++O///5Dw4YNoVQq8ddff6F8+fLo0KFDllkaNGiA1atX486dO9kaL6Svr4/p06cjICAA8+fPx7hx4wAAP/zwA65fv676NzAwEBYWFvj7778xa9YsxMbG4s8//4SFhYVqWekF0YQJE3DhwgV06tQJJUqUQHR0NE6ePInly5dj0qRJqFOnjmqe8+fPw8bGRrV9KA9IOpyZCqysrnMjRNo1QUqWLCnKli0rUlNThRBCXL9+XQQEBIhixYoJfX194eDgIBo1apThrIPw8HDRs2dP4eDgoLqGTUBAgHj+/Llqmnfv3olx48apruGRfr2N4cOHq51R9OHZHumio6OFkZHRR8/UePnypRgyZIhwc3MT+vr6wtraWnh7e4uxY8eqrqeTftbRrFmzNNp27969E9OnTxeenp7C2NhYGBsbiypVqoipU6dmuFaPEP+7bsrixYtF6dKlhb6+vvDw8Mj0omDayD1z5kzh6uoqDAwMRPny5cWKFStU1zB537Vr10SdOnWEsbFxtq9z86HMlvv48WPRtm1bYWpqKszMzES7du3Evn37BADxxx9/fHTbprt//74YOHCgKFOmjDAwMBBGRkaiQoUKIigoSO1Mnqwu4tetW7cMZyJld7uk/7wys3r1alGuXDlhYGAgSpUqJWbMmCFWrVqV6RlG69atE1988YUwNDQUpqamwsvLS+1ssdevX4v27dsLS0tLIZPJ1HKkpKSI2bNni6pVq6rm9/DwEP369RN3795VTZd+nZvMfPj5mTNnjqhdu7awtbUVcrlclCxZUvTq1Us8fPhQbb4xY8YIJycnoaOj88nr3CQkJIjx48errt9kY2MjGjVqJM6ePZtppnTR0dHC1NRU/PLLL2rtWV3nJl2NGjWElZWV2gUelUql2LBhg2jQoIGwtLQUcrlcuLm5iQEDBmQ48/B9f/zxh2jRooWws7MTenp6wsrKSjRs2FAsXbpU7WrESqVSuLi4iO++++6j74m0SybE/5+eQUT5kkwmw6BBg7Bw4UKpo0hm+vTpGDduHB4/fpzjXjMqXL777jscOXIEN2/e/OyzmXLTkSNH4Ovri5s3b8LDw0PqOEUGD0sRUb6SXsR5eHggJSUFR48exYIFC/Dtt9+ysCGVcePGYd26ddi+fbvqQpb50dSpU9GzZ08WNnmMxQ0R5SvGxsaYN28eHj58iKSkJJQsWRI//PCDapwEEZB2eYANGzbgzZs3UkfJ0ps3b1C/fn3VZS8o7/CwFBERERUqPBWciIiIChUWN0RERFSosLghIiKiQqXIDShWKpV49uwZzMzM8vXpg0RERPQ/QgjExsZm655kRa64efbsWY7u10JERETSCw8P/+RlIYpccZN+GfDw8HCYm5tLnIaIiIiyIyYmBiVKlMj0dh4fKnLFTfqhKHNzcxY3REREBUx2hpRwQDEREREVKixuiIiIqFBhcUNERESFCosbIiIiKlRY3BAREVGhwuKGiIiIChUWN0RERFSosLghIiKiQoXFDRERERUqLG6IiIioUJG0uDl58iRatmwJJycnyGQy7Nq165PznDhxAt7e3jA0NESpUqWwdOnS3A9KREREBYakxU1cXByqVq2KhQsXZmv6sLAw+Pv7o27durh69Sp+/PFHDBkyBNu3b8/lpERERFRQSHrjTD8/P/j5+WV7+qVLl6JkyZIIDg4GAJQvXx6XLl3C7Nmz0a5du1xKmUeEAFLjpU5BRESkHXrGQDZucpkrq5ZkrTl07tw5+Pr6qrU1a9YMq1atQkpKCvT19TPMk5SUhKSkJNXzmJiYXM/5SR8WMkIAm+sCL69JFomIiEirhrwD9E0kWXWBKm4iIyNhb2+v1mZvb4/U1FS8evUKjo6OGeaZMWMGJk2alFcRP04IICWOhQwRERUqcUn6eBlnAlfrt1JHAVDAihsAkH3QxSWEyLQ93ZgxYxAUFKR6HhMTgxIlSuRewPe930OTnd4ZO0+gwynJuvGIiIg09c8/LxHQaQ90dGS4cPZbGBv//1EUPWPJMhWo4sbBwQGRkZFqbS9evICenh5sbGwyncfAwAAGBgZ5EU+dUAK/e2ddzGRWyEh4fJKIiEgTQgisXn0VgwfvR2JiKpyczBD2JBkVK1pKHa1gFTe1atXCnj171NoOHToEHx+fTMfbSEaIrAub9KJG34SFDBERFUixsUkYMGAvNmy4AQBo3rwM1q1rDTs7acbYfEjS4ubdu3e4d++e6nlYWBiuXbsGa2trlCxZEmPGjMHTp0+xbt06AED//v2xcOFCBAUFoU+fPjh37hxWrVqFTZs2SfUWMpca/7/Cxqos8O2V/xUy7J0hIqIC7Pr1SAQEbMOdO1HQ1ZVh2rRG+P77OtDRyT/7NkmLm0uXLqFhw4aq5+ljY7p164a1a9ciIiICjx8/Vr3u5uaGffv2Yfjw4Vi0aBGcnJywYMGC/Hca+P+PAwKQVtjITaXLQkREpEWjRh3GnTtRcHY2x+bN7VCnTkmpI2UgE+L9PXHhFxMTAwsLC0RHR8Pc3Fz7KxAC+L3a/3puJDwVjoiISNuePo3BmDFHMG9eM9jY5N2gYU3237y3lLa9f0jKzlPS0eJERESf6/LlZ5g587TqefHi5li3rk2eFjaaKlADigscntZNREQFlBACCxdewMiRoUhOVqBiRTu0bFlO6ljZwuImN7GwISKiAujNmwT06rUbO3f+CwBo3doDX36Z/8bWZIXFDREREan89dcTdOiwHQ8fvoVcrovZs5ti8ODqWV4sNz9icUNEREQAgCVLLmLIkANITVWiVCkrbNnSHt7eTlLH0hiLGyIiIgIAFCtmgtRUJb75pgJWrGgJCwtDqSPlCIsbIiKiIiwuLhkmJnIAQLt2FXDyZHd8+WXJAnUY6kM8FZyIiKgIUioFZs48jbJlf8WzZ7Gq9rp1XQp0YQOwuCEiIipyXr6MQ4sWGzFmzBFERLzDunXXpY6kVTwsRUREVIScPPkIHTtux7NnsTA01MPChX7o2dNL6lhaxeKGiIioCFAolJgx4zQmTDgOpVKgfHlbbNnyDSpVKiZ1NK1jcUNERFQEBAefx08/HQMAdOtWFYsW+asGEhc2HHNDRERUBPTv74MvvnDC2rVfY+3a1oW2sAHYc0NERFQoKRRKbNhwA99+WwU6OjKYmMhx/nxv6OgU7DOhsoPFDRERUSHz7FksOnXajhMnHiEy8h1GjaoDAEWisAFY3BARERUqBw/ew7ff7sSrV/EwNZWjRAlzqSPlORY3REREhUBqqhI//XQUM2eeAQBUrWqPLVu+gbu7jcTJ8h6LGyIiogLuyZMYdOy4HadPPwYADBjgg7lzm8HQsGju5ovmuyYiIipEIiPf4a+/nsDc3AArVrREQEBFqSNJisUNERFRASSEUN0DysfHCevXt4W3tyNKl7aWOJn0eJ0bIiKiAubhw7do2PA3XL0aoWoLCKjIwub/sbghIiIqQHbt+hdeXstw4sQj9Ov3J4QQUkfKd1jcEBERFQDJyQoMG3YAbdqE4O3bRNSoURxbtnyjOjRF/8MxN0RERPncgwdvEBi4DZcuPQMAjBhRC9OnN4ZcritxsvyJxQ0REVE+dvv2S9SsuQoxMUmwtjbCb7+1xldfuUsdK19jcUNERJSPlStni5o1nREXl4xNm9qhRAkLqSPleyxuiIiI8pl7917DyckMxsb60NGRISSkPUxM9KGvz8NQ2cEBxURERPnIpk034OW1DEOG7Fe1WVoasrDRAHtuiIiI8oGEhBQMGbIfK1deBQDcvfsaCQkpMDLSlzhZwcPihoiISGK3b79EQMA2/PPPC8hkwLhx9TB+fH3o6fEAS06wuCEiIpLQunXXMWDAXsTHp8De3gTr17dFkyalpI5VoLG4ISIiksibNwkICjqI+PgUNG7shvXr28LBwVTqWAUeixsiIiKJWFkZYd26Nrh8+Rl+/LEudHV5GEobWNwQERHlESEEVq++CltbY3z9tQcAwN+/LPz9y0qcrHBhcUNERJQHYmOTMGDAXmzYcAOWloa4ebM4nJzMpI5VKLG4ISIiymXXr0ciIGAb7tyJgq6uDD/8UIdja3IRixsiIqJcIoTAsmWXMWzYASQlKeDsbI5Nm9rhyy9LSh2tUGNxQ0RElAtSU5Xo3HkHtmy5CQBo0aIsfvutNWxsjCVOVvhxWDYREVEu0NPTga2tEfT0dDB7dlPs3t2RhU0eYc8NERGRlgghEBeXAlNTOQBgzpxm6NnTC97eThInK1rYc0NERKQFb94koF27LWjVahMUCiUAwNBQj4WNBNhzQ0RE9JkuXHiKwMBtePjwLfT1dXDx4jPUrOksdawiiz03REREOSSEwNy551Cnzmo8fPgWpUpZ4ezZXixsJMaeGyIiohx4/ToB3bvvwp49dwAA7dtXwMqVLWFhYShxMmJxQ0RElAOdOm3HwYP3YWCgi3nzmqF/fx/IZDKpYxFY3BAREeXIrFlNERn5DmvXtoanp4PUceg9HHNDRESUDS9fxmHHjtuq55Ur2+PKlX4sbPIhFjdERESfcPLkI3h6LkNg4DacP/9E1a6jw8NQ+RGLGyIioiwoFEpMnXoSDRv+hmfPYlGmjLXqAn2Uf3HMDRERUSaeP3+Hzp134MiRMABA165VsWiRP4ubAoDFDRER0QeOHg1Dp07b8fx5HIyN9bFokT+6d/eUOhZlE4sbIiKiD9y48RzPn8ehYkU7bNnyDSpUsJM6EmmAxQ0RERHSrjacfp2aIUNqQF9fF927e8LYWF/iZKQpDigmIqIi79Ch+6hXby1iY5MAADKZDAMHfsHCpoBicUNEREVWaqoSP/54BM2arcfp048xc+ZpqSORFvCwFBERFUlPnsSgY8ftOH36MQCgf39v/PRTfYlTkTZI3nOzePFiuLm5wdDQEN7e3jh16tRHp9+wYQOqVq0KY2NjODo6okePHoiKisqjtEREVBjs3XsHnp5Lcfr0Y5iZyRES0h5LlnwFQ0P+zV8YSFrchISEYNiwYRg7diyuXr2KunXrws/PD48fP850+tOnT6Nr167o1asXbt68ia1bt+LixYvo3bt3HicnIqKCavXqq/jqq02IikpAtWqOuHq1HwICKkodi7RI0uJm7ty56NWrF3r37o3y5csjODgYJUqUwJIlSzKd/vz583B1dcWQIUPg5uaGL7/8Ev369cOlS5fyODkRERVULVqUhaOjKb77rjrOnu2J0qWtpY5EWiZZcZOcnIzLly/D19dXrd3X1xdnz57NdJ7atWvjyZMn2LdvH4QQeP78ObZt24YWLVpkuZ6kpCTExMSoPXKVELm7fCIi0ti1a5Gq/9vbm+KffwZiwQI/GBjwMFRhJFlx8+rVKygUCtjb26u129vbIzIyMtN5ateujQ0bNiAwMBByuRwODg6wtLTEr7/+muV6ZsyYAQsLC9WjRIkSWn0faoQANtfNveUTEZFGkpMVGDbsALy8lmHTphuqdmtrIwlTUW6TfEBx+gWT0r1/EaUP3bp1C0OGDMH48eNx+fJlHDhwAGFhYejfv3+Wyx8zZgyio6NVj/DwcK3mV5MaD7y8lvZ/O09Azzj31kVERB/14MEb1KmzGvPn/wUAuH37lcSJKK9I1h9na2sLXV3dDL00L168yNCbk27GjBmoU6cOvv/+ewBAlSpVYGJigrp162Lq1KlwdHTMMI+BgQEMDAy0/wY+pcMpIIsijYiIcte2bbfQq9duxMQkwcrKEL/91hotW5aTOhblEcl6buRyOby9vREaGqrWHhoaitq1a2c6T3x8PHR01CPr6uoCSOvxyVdY2BAR5bnExFQMGrQX33yzFTExSahduwSuXevPwqaIkfSwVFBQEFauXInVq1fj9u3bGD58OB4/fqw6zDRmzBh07dpVNX3Lli2xY8cOLFmyBA8ePMCZM2cwZMgQVK9eHU5OTlK9DSIiyifOng3H4sVpZ9D+8EMdHD/eDSVLWkicivKapMPEAwMDERUVhcmTJyMiIgKVKlXCvn374OLiAgCIiIhQu+ZN9+7dERsbi4ULF2LEiBGwtLREo0aN8PPPP0v1FoiIKB9p1MgNU6c2RLVqjvDzKyt1HJKITOS74zm5KyYmBhYWFoiOjoa5ubl2F54SBywwTfv/kHeAvol2l09ERGoSElLw449HMGxYTbi4WEodh3KRJvtvnuBPREQF0r//vkJAwFbcuPECFy8+w6lTPbI825aKFhY3RERU4Kxbdx0DBuxFfHwKihUzwcSJDVjYkAqLGyIiKjDi4pIxePB+rF17DUDaGJv169vA0dFM2mCUr7C4ISKiAuHRo7fw99+IW7deQkdHhgkT6mPs2LrQ1ZX8erSUz7C4ISKiAsHe3hT6+jpwdDTFxo3t0KCBq9SRKJ9icUNERPnWu3fJMDLSg66uDgwN9bBjRyBMTeUoVoxno1LW2JdHRET50vXrkfD2Xo6pU0+q2kqVsmJhQ5/E4oaIiPIVIQSWLbuEGjVW4s6dKKxefQ1xcclSx6IChMUNERHlGzExSejYcTv699+LpCQF/P3L4vLlvjAxkUsdjQoQjrkhIqJ84cqVCAQEbMX9+2+gp6eDGTMaIyioFnR0eP0a0gyLGyIiklxMTBIaNfoN0dFJKFnSAiEh7VGzprPUsaiAYnFDRESSMzc3wKxZTbF3712sXv01rK2NpI5EBRiLGyIiksSFC08hkwFffFEcANC7dzX07l2Nt1Ggz8YBxURElKeEEJg79xzq1FmNb77ZijdvEgAAMpmMhQ1pBXtuiIgoz7x+nYDu3Xdhz547AAAfHycOGCatY3FDRER54uzZcHTosA3h4TGQy3Uxb14zDBjgw94a0joWN0RElKuUSoHZs8/ixx+PQKEQKFPGGlu2tIeXl6PU0aiQYnFDRES5SiYDzpwJh0Ih0KFDJSxb9hXMzQ2kjkWFGIsbIiLKFUII1SDhNWu+xp49/6Fr16o8DEW5jmdLERGRVimVAtOmnUSPHn9ACAEAsLY2QrdunixsKE+w54aIiLTm+fN36NJlJ0JDHwAAunWrioYN3SRORUUNixsiItKKo0fD0LnzDkRGvoORkR4WLfJHgwauUseiIojFDRERfRaFQokpU05i8uQTEAKoUMEOW7d+gwoV7KSORkUUixsiIvosXbrsxKZN/wAAevb0xK+/+sPYWF/iVFSUcUAxERF9ll69vGBuboDff2+DVau+ZmFDkmPPDRERaSQ1VYmbN1+galUHAEDjxqXw8OFQWFnxTt6UP7DnhoiIsu3Jkxg0avQb6tZdg3v3XqvaWdhQfsLihoiIsmXfvrvw9FyKU6ceA4BacUOUn/CwFBERfVRKigJjxx7FrFlnAQDVqjkiJKQ9ypSxljgZUeZY3BARUZYeP45Ghw7bcO7cEwDA4MFfYPZsXxgYcPdB+Rd/O4mIKEvLl1/GuXNPYGFhgFWrWqFduwpSRyL6JBY3RESUpfHj6+PVq3j88EMduLlZSR2HKFs4oJiIiFTCwt5gwIA/kZKiAADI5bpYuvQrFjZUoOSouElNTcXhw4exbNkyxMbGAgCePXuGd+/eaTUcERHlne3bb8HLaxmWLr2MqVNPSh2HKMc0Piz16NEjNG/eHI8fP0ZSUhKaNm0KMzMz/PLLL0hMTMTSpUtzI2fBIITUCYiINJaYmIqRIw9h0aKLAIBatZzRq1c1iVMR5ZzGPTdDhw6Fj48P3rx5AyOj/120qU2bNjhy5IhWwxUoQgCb60qdgohII/fuvUbt2qtUhc2oUbVx4kR3lCxpIXEyopzTuOfm9OnTOHPmDORyuVq7i4sLnj59qrVgBU5qPPDyWtr/7TwBPWMp0xARfdK+fXfRocM2xMYmw8bGCOvWtYG/f1mpYxF9No2LG6VSCYVCkaH9yZMnMDMz00qoAq/DKUAmkzoFEdFHlS5tBaVSoG7dkti4sR2cnc2ljkSkFRoflmratCmCg4NVz2UyGd69e4cJEybA399fm9kKLhY2RJRPvX2bqPp/uXK2OHWqB44e7cbChgoVjYubefPm4cSJE6hQoQISExPRqVMnuLq64unTp/j5559zIyMREWnB+vV/w8UlGCdOPFS1eXk5Qk+PVwWhwkXjw1JOTk64du0aNm/ejMuXL0OpVKJXr17o3Lmz2gBjIiLKH+LjUzB48D6sWXMNALB8+RXUr+8qaSai3KRxcXPy5EnUrl0bPXr0QI8ePVTtqampOHnyJOrVq6fVgERElHM3b75AQMA23Lr1EjIZMGFCfYwbx+9pKtw0Lm4aNmyIiIgIFCtWTK09OjoaDRs2zHSwMRER5S0hBNauvYZBg/YhISEVDg6m2LixLRo2dJM6GlGu07i4EUJAlsmA2aioKJiYmGglFBERfZ5jxx6iZ8/dAICmTUth/fq2KFaM39FUNGS7uGnbti2AtLOjunfvDgMDA9VrCoUCf//9N2rXrq39hEREpLGGDV3RuXNlVKhgh9Gjv4SODs/ipKIj28WNhUXa1SqFEDAzM1MbPCyXy1GzZk306dNH+wmJiOiThBD4/fe/0bKlO6ysjCCTyfD7720y7WknKuyyXdysWbMGAODq6oqRI0fyEBQRUT4RE5OEfv3+xObN/6BNGw9s3x4AmUzGwoaKLI3H3EyYMCE3chARUQ5cvRqBgIBtuHfvNXR1ZahVyxlC8FqiVLRpXNwAwLZt27BlyxY8fvwYycnJaq9duXJFK8GIiChrQggsXnwRQUGHkJysQMmSFti8uR1q1SohdTQiyWl8WcoFCxagR48eKFasGK5evYrq1avDxsYGDx48gJ+fX25kJCKi97x9m4hvvtmKwYP3IzlZgVatyuHq1X4sbIj+n8bFzeLFi7F8+XIsXLgQcrkco0aNQmhoKIYMGYLo6OjcyEhERO9RKJS4cOEp9PV1MG9eM+zaFQhra14hniidxoelHj9+rDrl28jICLGxsQCALl26oGbNmli4cKF2ExIREYQQANIux2FjY4ytW7+Bjo4MX3xRXOJkRPmPxj03Dg4OiIqKAgC4uLjg/PnzAICwsDDVh4+IiLTn9esEtG4doro3FADUqOHMwoYoCxoXN40aNcKePXsAAL169cLw4cPRtGlTBAYGok2bNloPSERUlJ07Fw4vr2XYvfs/jBhxCDExSVJHIsr3ND4stXz5ciiVSgBA//79YW1tjdOnT6Nly5bo37+/1gMSERVFSqXAnDln8eOPR5GaqkTp0lbYsuUbmJsbfHpmoiJO4+JGR0cHOjr/6/AJCAhAQEAAAODp06coXpzdpEREn+PVq3h067YL+/bdBQAEBlbE8uUtWdgQZZPGh6UyExkZie+++w5lypTReN7FixfDzc0NhoaG8Pb2xqlTpz46fVJSEsaOHQsXFxcYGBigdOnSWL16dU6jExHlK+/eJcPbezn27bsLAwNdLFv2FTZtasfChkgD2S5u3r59i86dO8POzg5OTk5YsGABlEolxo8fj1KlSuH8+fMaFxkhISEYNmwYxo4di6tXr6Ju3brw8/PD48ePs5wnICAAR44cwapVq/Dff/9h06ZN8PDw0Gi9RET5lampHN26VUW5cja4cKEP+vb15m0UiDQkE9k8xWngwIHYs2cPAgMDceDAAdy+fRvNmjVDYmIiJkyYgPr162u88ho1aqBatWpYsmSJqq18+fJo3bo1ZsyYkWH6AwcOoEOHDnjw4AGsra01Xh8AxMTEwMLCAtHR0TA3N8/RMjKVEgcsME37/5B3gD7vvUVE2fPiRRzi41Pg6moJAEhNVSIxMRWmpnJpgxHlI5rsv7Pdc7N3716sWbMGs2fPxu7duyGEgLu7O44ePZqjwiY5ORmXL1+Gr6+vWruvry/Onj2b6Ty7d++Gj48PfvnlFxQvXhzu7u4YOXIkEhISslxPUlISYmJi1B5ERPnFsWNhqFp1Kdq124KkpFQAgJ6eDgsbos+Q7QHFz549Q4UKFQAApUqVgqGhIXr37p3jFb969QoKhQL29vZq7fb29oiMjMx0ngcPHuD06dMwNDTEzp078erVKwwcOBCvX7/O8pDYjBkzMGnSpBznJCLKDQqFElOnnsTkySehVApYWxvhxYs4lChhIXU0ogIv2z03SqUS+vr6que6urowMfn8Qy8fHksWQmR5fFmpVEImk2HDhg2oXr06/P39MXfuXKxduzbL3psxY8YgOjpa9QgPD//szEREnyMiIha+vusxceIJKJUCPXp44sKF3ixsiLQk2z03Qgh0794dBgZpI/YTExPRv3//DAXOjh07srU8W1tb6OrqZuilefHiRYbenHSOjo4oXrw4LCz+9wVQvnx5CCHw5MkTlC1bNsM8BgYGqsxERFILDb2Pb7/diRcv4mBioo8lS1qgS5eqUsciKlSy3XPTrVs3FCtWDBYWFrCwsMC3334LJycn1fP0R3bJ5XJ4e3sjNDRUrT00NFR176oP1alTB8+ePcO7d+9UbXfu3IGOjg6cnZ2zvW4iIikIITB+/HG8eBGHypWL4dKlvixsiHJBts+Wyg0hISHo0qULli5dilq1amH58uVYsWIFbt68CRcXF4wZMwZPnz7FunXrAADv3r1D+fLlUbNmTUyaNAmvXr1C7969Ub9+faxYsSJb6+TZUkQkpbCwN5g//y/MmNEYRkb6n56BiABotv/W+ArF2hQYGIioqChMnjwZERERqFSpEvbt2wcXFxcAQEREhNo1b0xNTREaGorvvvsOPj4+sLGxQUBAAKZOnSrVWyAi+qj9++/i+vXnGD36SwCAm5sVgoObS5yKqHCTtOdGCuy5IaK8kJKiwLhxR/HLL2mXtjh+vBvq13eVNhRRAVZgem6IiAqjx4+j0aHDNpw79wQAMGjQF6hRg+MCifIKixsiIi3avfs/dO++C2/eJMLCwgCrVrVCu3YVpI5FVKSwuCEi0pJx445i2rS0m/9+8YUTNm9uj1KlrCRORVT05Oiu4L///jvq1KkDJycnPHr0CAAQHByMP/74Q6vhiIgKknLlbAAAw4bVwOnTPVnYEElE4+JmyZIlCAoKgr+/P96+fQuFQgEAsLS0RHBwsLbzERHla2/e/O/q6F26VMXly30xb15zyOW6EqYiKto0Lm5+/fVXrFixAmPHjoWu7v8+vD4+Prhx44ZWwxER5VdJSan47rt9qFx5CV6+jFO1V6vmKGEqIgJyUNyEhYXBy8srQ7uBgQHi4uIymYOIqHC5d+81atdejYULL+Lp01js3XtX6khE9B6Nixs3Nzdcu3YtQ/v+/ftVdw0nIiqstmy5iWrVluHKlQjY2Bjhzz87ont3T6ljEdF7ND5b6vvvv8egQYOQmJgIIQQuXLiATZs2YcaMGVi5cmVuZCQiklxCQgqGDz+IZcsuAwC+/LIkNm1qB2dnLV4MlIi0QuPipkePHkhNTcWoUaMQHx+PTp06oXjx4pg/fz46dOiQGxmJiCQ3efIJLFt2GTIZMGbMl5g0qSH09HJ0wikR5bLPuv3Cq1evoFQqUaxYMW1mylW8/QIR5UR0dCL8/DZg4sQG8PUtLXUcoiJHk/23xn92TJo0Cffv3wcA2NraFqjChogou+LjU7BkyUWk//1nYWGIM2d6srAhKgA0Lm62b98Od3d31KxZEwsXLsTLly9zIxcRkWRu3XqJ6tVXYODAfVi8+KKqXSaTSZiKiLJL4+Lm77//xt9//41GjRph7ty5KF68OPz9/bFx40bEx8fnRkYiojyzdu01fPHFCty8+RIODqYoX95O6khEpKEcjYarWLEipk+fjgcPHuDYsWNwc3PDsGHD4ODgoO18RER54t27ZHTrtgs9evyB+PgUNGlSCteu9UOjRm5SRyMiDX32jTNNTExgZGQEuVyO2NhYbWQiIspTN248R0DANvz77yvo6MgweXIDjBlTFzo6PAxFVBDlqOcmLCwM06ZNQ4UKFeDj44MrV65g4sSJiIyM1HY+IqJcFx2dhLt3o+DkZIZjx7ph7Nh6LGyICjCNe25q1aqFCxcuoHLlyujRo4fqOjdERAWJEEI1QPjLL0ti8+b2qF/fBXZ2vIwDUUGncXHTsGFDrFy5EhUrVsyNPEREue7q1Qj07LkbGza0RYUKaQOG27fn7WOICguND0tNnz6dhQ0RFUhCCCxefBE1a67CtWuRGDHikNSRiCgXZKvnJigoCFOmTIGJiQmCgoI+Ou3cuXO1EoyISJuioxPRu/cebNt2CwDQsqU71qz5WuJURJQbslXcXL16FSkpKar/ExEVJJcuPUNAwFaEhb2Fvr4Ofv65CYYNq8mL8hEVUtkqbo4dO5bp/4mI8rtz58JRv/5apKQo4epqiZCQ9qhenSdBEBVmGo+56dmzZ6bXs4mLi0PPnj21EoqISFu++KI4atZ0Rtu25XH1aj8WNkRFgMZ3BdfV1UVERESGG2a+evUKDg4OSE1N1WpAbeNdwYkKvytXIlCxoh0MDNI6p2Njk2BqKudhKKICLFfuCh4TE4Po6GgIIRAbG4uYmBjV482bN9i3bx/vEE5EklIqBWbPPosaNVZi1KhQVbuZmQELG6IiJNvXubG0tIRMJoNMJoO7u3uG12UyGSZNmqTVcERE2fXqVTy6d9+FvXvvAgCeP4+DQqGErm6OLsRORAVYtoubY8eOQQiBRo0aYfv27bC2tla9JpfL4eLiAicnp1wJSUT0MadPP0aHDtvw9GksDAx0MX9+c/Tt683eGqIiKtvFTf369QGk3VeqZMmS/NIgIskplQI//3waP/10DAqFgLu7DbZsaY+qVR2kjkZEEspWcfP333+jUqVK0NHRQXR0NG7cuJHltFWqVNFaOCKij3n2LBYzZ56BQiHQuXNlLFnSAmZmBlLHIiKJZau48fT0RGRkJIoVKwZPT0/IZDJkdpKVTCaDQqHQekgiosw4O5tj7dqv8eZNInr08GSPMhEByGZxExYWBjs7O9X/iYikoFAoMX36KVSvXhzNmpUBALRpU17iVESU32SruHFxccn0/0REeSUy8h06d96Bo0fDYGtrjDt3BsPKykjqWESUD2l8juRvv/2GvXv3qp6PGjUKlpaWqF27Nh49eqTVcEREAHD48ANUrboUR4+GwcREH3Pn+rKwIaIsaVzcTJ8+HUZGaV8q586dw8KFC/HLL7/A1tYWw4cP13pAIiq6UlOV+Omno/D1/R0vXsShcuViuHSpL7p0qSp1NCLKx7J9Kni68PBwlCmTdqx7165daN++Pfr27Ys6deqgQYMG2s5HREVUfHwK/Pw24OTJtB7hvn2rITi4OYyM9CVORkT5ncY9N6ampoiKigIAHDp0CE2aNAEAGBoaIiEhQbvpiKjIMjbWh5ubJUxN5di0qR2WLWvJwoaIskXjnpumTZuid+/e8PLywp07d9CiRQsAwM2bN+Hq6qrtfERUhKSkKBAfnwILC0MAwKJF/hg3rh7KlLH+xJxERP+jcc/NokWLUKtWLbx8+RLbt2+HjY0NAODy5cvo2LGj1gMSUdEQHh6NBg1+Q8eO26FUpl1Hy8REzsKGiDQmE5ldja8Q0+SW6RpJiQMWmKb9f8g7QN9Ee8smKuT27PkP3bv/gdevE2BuboC//uoNDw9bqWMRUT6iyf5b48NSAPD27VusWrUKt2/fhkwmQ/ny5dGrVy9YWFjkKDARFU3JyQqMGXMYc+eeBwD4+DghJKQ9SpWykjgZERVkGh+WunTpEkqXLo158+bh9evXePXqFebNm4fSpUvjypUruZGRiAqhhw/fom7dNarCZtiwGjh9ugcLGyL6bBr33AwfPhytWrXCihUroKeXNntqaip69+6NYcOG4eTJk1oPSUSFixAC7dtvweXLEbC0NMTatV/j6689pI5FRIVEjnpufvjhB1VhAwB6enoYNWoULl26pNVwRFQ4yWQyLF36FerVc8G1a/1Y2BCRVmlc3Jibm+Px48cZ2sPDw2FmZqaVUERU+Ny//xrbtt1SPffxccLx493g4mIpXSgiKpQ0PiwVGBiIXr16Yfbs2ahduzZkMhlOnz6N77//nqeCE1Gmtm69id699yAxMRWlS1vBy8sRQFoPDhGRtmlc3MyePRsymQxdu3ZFamoqAEBfXx8DBgzAzJkztR6QiAquxMRUBAUdxJIlaYesv/yyJOzseJkEIspdOb7OTXx8PO7fvw8hBMqUKQNjY2NtZ8sVvM4NUd64cycKAQFbcf36c8hkwJgxX2LSpIbQ09P4aDgRkUb772x/y8THx2PQoEEoXrw4ihUrht69e8PR0RFVqlQpMIUNEeWNjRtvoFq1Zbh+/Tns7Ixx4MC3mDatMQsbIsoT2f6mmTBhAtauXYsWLVqgQ4cOCA0NxYABA3IzGxEVUA8fvkVcXAoaNHDFtWv94etbWupIRFSEZHvMzY4dO7Bq1Sp06NABAPDtt9+iTp06UCgU0NXVzbWARFQwKJUCOjppA4RHj/4STk5m6NKlCnR12VtDRHkr29864eHhqFu3rup59erVoaenh2fPnuVKMCIqOH777Rpq116F+PgUAICOjgzdu3uysCEiSWT7m0ehUEAul6u16enpqc6YIqKiJy4uGd267UL37n/gr7+eYtkyXsiTiKSX7cNSQgh0794dBgYGqrbExET0798fJib/OzNox44d2k1IRPnSjRvPERCwDf/++wo6OjJMntwAQ4bUkDoWEVH2i5tu3bplaPv222+1GoaI8j8hBFatuorvvtuPxMRUODmZYdOmdqhXz0XqaEREADQobtasWZObOYiogJg58zR+/PEoAMDPrwx++601L8xHRPmK5KP9Fi9eDDc3NxgaGsLb2xunTp3K1nxnzpyBnp4ePD09czcgEanp0qUqHBxM8fPPTfDnn51Y2BBRviNpcRMSEoJhw4Zh7NixuHr1KurWrQs/P79Mb8z5vujoaHTt2hWNGzfOo6RERZcQAmfO/O8z6exsjrt3v8OoUXVUp34TEeUnkhY3c+fORa9evdC7d2+UL18ewcHBKFGiBJYsWfLR+fr164dOnTqhVq1aeZSUqGiKjk5EQMA2fPnlGvzxx7+qdlNT+UfmIiKSlmTFTXJyMi5fvgxfX1+1dl9fX5w9ezbL+dasWYP79+9jwoQJuR2RqEi7dOkZqlVbjm3bbkFfXwcREe+kjkRElC0a3xVcW169egWFQgF7e3u1dnt7e0RGRmY6z927dzF69GicOnUKenrZi56UlISkpCTV85iYmJyHJioChBBYsOAvfP99KFJSlHB1tURISHtUr15c6mhERNmSo56b33//HXXq1IGTkxMePXoEAAgODsYff/yh8bJkMvVj9kKIDG1A2kUEO3XqhEmTJsHd3T3by58xYwYsLCxUjxIlSmickaioePMmAW3bbsGwYQeRkqJE27blcfVqPxY2RFSgaFzcLFmyBEFBQfD398fbt2+hUCgAAJaWlggODs72cmxtbaGrq5uhl+bFixcZenMAIDY2FpcuXcLgwYOhp6cHPT09TJ48GdevX4eenh6OHj2a6XrGjBmD6Oho1SM8PDz7b5aoiDl58hF27foXcrkufv3VD9u2fQNLS0OpYxERaUTj4ubXX3/FihUrMHbsWLUbZvr4+ODGjRvZXo5cLoe3tzdCQ0PV2kNDQ1G7du0M05ubm+PGjRu4du2a6tG/f3+UK1cO165dQ40amV8Z1cDAAObm5moPIsrc1197YOrUhjh7ticGD66eaS8qEVF+p/GYm7CwMHh5eWVoNzAwQFxcnEbLCgoKQpcuXeDj44NatWph+fLlePz4Mfr37w8grdfl6dOnWLduHXR0dFCpUiW1+YsVKwZDQ8MM7USUPVFR8Rgx4hBmzGgMR0czAMDYsfUkTkVE9Hk0Lm7c3Nxw7do1uLioX2p9//79qFChgkbLCgwMRFRUFCZPnoyIiAhUqlQJ+/btUy07IiLik9e8IaKcOXPmMTp02I4nT2Lw4kUc9u3rLHUkIiKtkAkhhCYzrFmzBj/99BPmzJmDXr16YeXKlbh//z5mzJiBlStXokOHDrmVVStiYmJgYWGB6Oho7R6iSokDFpim/X/IO0CfV22l/EmpFPjllzMYN+4oFAoBd3cbbNnSHlWrOkgdjYgoS5rsvzXuuenRowdSU1MxatQoxMfHo1OnTihevDjmz5+f7wsboqLu5cs4dO26CwcO3AMAdO5cGUuWtICZmYHEyYiItCdH17np06cP+vTpg1evXkGpVKJYsWLazkVEWvbPPy/QrNl6PHsWCyMjPSxc6I8ePTw5aJiICp3Puoifra2ttnIQUS5zdbWEubkBLCwMsGXLN6hUiX+UEFHhlKMBxR/7S+/BgwefFYiItCcqKh5WVkbQ0ZHB1FSOffs6oVgxE5iY8N5QRFR4aVzcDBs2TO15SkoKrl69igMHDuD777/XVi4i+kxHjjxA5847MHJkbYwcmXbtKDc3K4lTERHlPo2Lm6FDh2bavmjRIly6dOmzAxHR51EolJg06QSmTj0JIYCNG29g2LCa0NOT7D65RER5Smvfdn5+fti+fbu2FkdEOfDsWSwaN16HKVPSCps+farhzJmeLGyIqEjR2l3Bt23bBmtra20tjog0dPDgPXz77U68ehUPU1M5li//Ch07VpY6FhFRntO4uPHy8lIbUCyEQGRkJF6+fInFixdrNRwRZU9ERCy+/nozkpIU8PR0QEhIe7i720gdi4hIEhoXN61bt1Z7rqOjAzs7OzRo0AAeHh7aykVEGnB0NMPPPzfBnTtRmDOnGQwNtdYpS0RU4Gj0DZiamgpXV1c0a9YMDg68VDuRlPbuvYPixc3h6Zn2WRw6tKbEiYiI8geNRhnq6elhwIABSEpKyq08RPQJyckKjBx5CF99tQkBAVsRG8vPIxHR+zTuu65RowauXr2a4a7gRJT7Hj58iw4dtuGvv54CAFq0KAu5XFfiVERE+YvGxc3AgQMxYsQIPHnyBN7e3jAxUb/7dZUqVbQWjoj+Z9euf9Gjxx94+zYRlpaGWLv2a3z9Nce5ERF9KNvFTc+ePREcHIzAwEAAwJAhQ1SvyWQyCCEgk8mgUCi0n5KoCEtJSTsMtWDBBQBAzZrO2Ly5HVxcLKUNRkSUT2W7uPntt98wc+ZMhIWF5WYeIvqAjo4Mt269AgCMHFkL06c3hr4+D0UREWUl28WNEAIAONaGKI8olQI6OjLo6upg/fo2uHw5Av7+ZaWORUSU72l0ttTH7gZORNqRmJiKgQP3YsCAP1Vt9vamLGyIiLJJowHF7u7unyxwXr9+/VmBiIqyu3ejEBCwDdeuRQIABg2qjipV7CVORURUsGhU3EyaNAkWFha5lYWoSNu06Qb69v0T794lw87OGL//3oaFDRFRDmhU3HTo0AHFihXLrSxERVJCQgqGDNmPlSuvAgAaNHDFhg1t4eRkJnEyIqKCKdvFDcfbEGmfEAL+/htx/PhDyGTATz/Vw/jx9aGrq9FwOCIieo/GZ0sRkfbIZDKMHFkL//33CuvXt0WjRm5SRyIiKvCyXdwolcrczEFUZMTFJeP27Vfw8XECALRo4Y67d7+DiYlc4mRERIUD+76J8tA//7zAF1+sgK/v73j06K2qnYUNEZH2sLghygNCCKxadQXVq6/A7duvYGSkj+fP46SORURUKGl840wi0kxsbBIGDNiLDRtuAACaNy+Ddetaw87O5BNzEhFRTrC4IcpF165FIjBwG+7ciYKurgzTpjXC99/XgY4Ozz4kIsotLG6IctGqVVdw504UnJ3NsXlzO9SpU1LqSEREhR6LG6JcNGuWL/T1dTF2bF3Y2BhLHYeIqEjggGIiLbp8+Rl69foDCkXapRMMDfUwd24zFjZERHmIPTdEWiCEwMKFFzByZCiSkxWoWLEYgoJqSR2LiKhIYnFD9JnevElAr167sXPnvwCA1q090KOHp7ShiIiKMBY3RJ/hwoWnCAzchocP30Iu18Xs2U0xeHB13ouNiEhCLG6Icmjduuvo1Ws3UlOVKFXKClu2tIe3t5PUsYiIijwWN0Q55OnpAD09HbRtWx7Ll38FCwtDqSMRERFY3BBp5MWLOBQrlnZl4SpV7HHlSl94eNjyMBQRUT7CU8GJskGpFPj559NwdQ3GX389UbWXL2/HwoaIKJ9hcUP0CS9fxqFFi40YPfoIEhJSsW3bLakjERHRR/CwFNFHnDz5CB07bsezZ7EwNNTDwoV+6NnTS+pYRET0ESxuiDKhUCgxY8ZpTJhwHEqlQPnyttiy5RtUqlRM6mhERPQJLG6IMrF9+2389NMxAEC3blWxaJE/TEzkEqciIqLsYHFDlIlvvqmAXbsqoVmz0ujWzVPqOEREpAEOKCZC2mGoefPOITY2CQAgk8mwcWM7FjZERAUQixsq8p49i0XjxusQFHQIAwbslToOERF9Jh6WoiLt4MF76NJlJ16+jIepqRz+/mWljkRERJ+JxQ0VSampSvz001HMnHkGAFC1qj22bPkG7u42EicjIqLPxeKGipynT2MQGLgNZ86EAwAGDvTBnDnNYGjIjwMRUWHAb3MqcnR1dXDv3muYmxtg5cqW+OabilJHIiIiLWJxQ0WCQqGErm7a+HkHB1Ps2BEIe3sTlC5tLXEyIiLSNp4tRYXew4dvUafOaoSE/KNqq127BAsbIqJCisUNFWq7dv0LL69l+Ouvpxg16jCSkxVSRyIiolzG4oYKpeRkBYYNO4A2bULw9m0iqlcvjhMnukMu15U6GhER5TKOuaFC58GDNwgM3IZLl54BAEaMqIXp0xuzsCEiKiJY3FCh8uJFHKpVW4bo6CRYWxth7dqv0bJlOaljERFRHmJxQ4VKsWIm6NXLC+fPP8Xmze1QooSF1JGIiCiPST7mZvHixXBzc4OhoSG8vb1x6tSpLKfdsWMHmjZtCjs7O5ibm6NWrVo4ePBgHqal/Oju3Sg8fhytej5zZhMcP96NhQ0RURElaXETEhKCYcOGYezYsbh69Srq1q0LPz8/PH78ONPpT548iaZNm2Lfvn24fPkyGjZsiJYtW+Lq1at5nJzyi02bbqBateXo2HE7UlLSzoTS19eFvj7H1xARFVUyIYSQauU1atRAtWrVsGTJElVb+fLl0bp1a8yYMSNby6hYsSICAwMxfvz4bE0fExMDCwsLREdHw9zcPEe5M5USBywwTfv/kHeAvon2lk0ZJCSkYOjQA1ix4goAoH59F+zYEQhrayOJkxERUW7QZP8tWc9NcnIyLl++DF9fX7V2X19fnD17NlvLUCqViI2NhbU1L8ZWlPz77ytUr74SK1ZcgUwG/PRTPRw+3JWFDRERAZBwQPGrV6+gUChgb2+v1m5vb4/IyMhsLWPOnDmIi4tDQEBAltMkJSUhKSlJ9TwmJiZngSlfWLfuOgYM2Iv4+BTY25tg/fq2aNKklNSxiIgoH5F8QLFMJlN7LoTI0JaZTZs2YeLEiQgJCUGxYsWynG7GjBmwsLBQPUqUKPHZmUkayckKzJlzDvHxKWjc2A3XrvVnYUNERBlIVtzY2tpCV1c3Qy/NixcvMvTmfCgkJAS9evXCli1b0KRJk49OO2bMGERHR6se4eHhn52dpCGX62LLlvaYNq0RDh78Fg4OplJHIiKifEiy4kYul8Pb2xuhoaFq7aGhoahdu3aW823atAndu3fHxo0b0aJFi0+ux8DAAObm5moPKhiEEFi16gp++eWMqq1cOVv8+GNd1R2+iYiIPiTpRfyCgoLQpUsX+Pj4oFatWli+fDkeP36M/v37A0jrdXn69CnWrVsHIK2w6dq1K+bPn4+aNWuqen2MjIxgYcFrmhQmsbFJGDBgLzZsuAEdHRmaNCmFatUcpY5FREQFgKTFTWBgIKKiojB58mRERESgUqVK2LdvH1xcXAAAERERate8WbZsGVJTUzFo0CAMGjRI1d6tWzesXbs2r+NTLrl+PRIBAdtw504UdHVlmDq1ETw9HaSORUREBYSk17mRAq9zk38JIbB8+WUMHXoASUkKODubY9Omdvjyy5JSRyMiIolpsv/mvaUo3+jZczfWrr0GAPjqK3esXfs1bGyMpQ1FREQFDkdlUr5Rs2Zx6OnpYPbspti9uwMLGyIiyhH23JBkhBB4/jxOdUp3377eaNDAFeXK2UqcjIiICjL23JAk3rxJQLt2W1Cr1iq8fZsIIO2CjixsiIjoc7G4oTz3119PUK3acuzc+S+ePo3BmTOZ3wWeiIgoJ1jcUJ4RQmDu3HP48ss1ePjwLUqVssLZs73QooW71NGIiKgQ4ZgbyhNRUfHo3v0P/PnnHQBA+/YVsHJlS1hYGEqcjIiIChsWN5QnRo8+jD//vAMDA13Mm9cM/fv7ZOsGqURERJpicUN5YubMJggLe4vZs315tWEiIspVHHNDueLlyzjMm3cO6RfAtrExxuHDXVnYEBFRrmPPDWndyZOP0LHjdjx7FgsLC0P07OkldSQiIipC2HNDWqNQKDF16kk0bPgbnj2LhYeHLb74wknqWEREVMSw54a04vnzd/j22504fPgBAKBr16pYtMgfpqZyiZMREVFRw+KGPtvx4w/RocM2PH8eB2NjfSxa5I/u3T2ljkVEREUUixv6bKmpSrx4EYeKFe2wZcs3qFDBTupIRERUhLG4oRxJTVVCTy9tyFaTJqWwc2cgmjYtDWNjfYmTERFRUccBxaSxgwfvoXz5Rbh//7Wq7euvPVjYEBFRvsDihrItNVWJH388gubNN+DevdeYPPmk1JGIiIgy4GEpypYnT2LQseN2nD6ddgfv/v29MXduM4lTERERZcTihj5p79476NZtF6KiEmBmJsfKla0QEFBR6lhERESZYnFDH/Xnn3fQsuUmAEC1ao4ICWmPMmWsJU5FRESUNRY39FG+vqVRvXpx1KhRHLNmNYWBAX9liIgof+OeijI4diwMX35ZEvr6upDLdXHiRHcYGvJXhYiICgaeLUUqyckKDBt2AI0arcOECcdV7SxsiIioIOFeiwAADx68QWDgNly69AwAkJKigBACMplM4mRERESaYXFD2LbtFnr12o2YmCRYWxth7dqv0bJlOaljERER5QiLmyIsMTEVI0YcxOLFlwAAtWuXwKZN7VCypIXEyYiIiHKOY26KsPDwaPz223UAwA8/1MHx491Y2BARUYHHnpsirGxZG6xe/TXMzOTw8ysrdRwiIiKtYM9NEZKQkIL+/f/EyZOPVG0BARVZ2BARUaHC4qaI+PffV6hRYyWWLbuMzp13IDExVepIREREuYKHpYqAdeuuY8CAvYiPT0GxYiZYvboVr11DRESFFvdwhVhcXDIGD96PtWuvAQAaNXLD+vVt4OhoJm0wIiKiXMTippB6/ToBdeuuwa1bL6GjI8OECfUxdmxd6OrySCQRERVuLG4KKSsrQ1SsaIc3bxKwcWM7NGjgKnUkIiKiPMHiphB59y4ZCoUSFhaGkMlkWLGiJZKSFChWzETqaERERHmGxygKievXI+HtvRy9eu2GEAIAYGFhyMKGiIiKHPbcFHBCCCxffhlDhx5AUpICcXHJiIh4BycnDhomIqKiicVNARYTk4S+ffcgJOQmAKBFi7JYu7Y1bG2NJU5GREQkHRY3BdSVKxEICNiK+/ffQE9PBzNmNEZQUC3o6MikjkZERCQpFjcFUGqqUlXYlCxpgZCQ9qhZ01nqWERERPkCBxQXQHp6Oli7tjXatSuPq1f7sbAhIiJ6D3tuCogLF57i8eNotG9fAQDw5Zcl8eWXJSVORURElP+wuMnnhBAIDj6PH344DH19XVSoYIcKFeykjkVERJRvsbjJx16/TkD37ruwZ88dAECrVuV4ijcREdEnsLjJp86eDUeHDtsQHh4DuVwX8+Y1w4ABPpDJeDYUUV4TQiA1NRUKhULqKESFmr6+PnR1dT97OSxu8qHZs89i9OjDUCgEypSxxpYt7eHl5Sh1LKIiKTk5GREREYiPj5c6ClGhJ5PJ4OzsDFNT089aDoubfOjt20QoFAIdOlTCsmVfwdzcQOpIREWSUqlEWFgYdHV14eTkBLlczt5TolwihMDLly/x5MkTlC1b9rN6cFjc5BOpqUro6aWdmT9xYgN4ezuidWsPfpESSSg5ORlKpRIlSpSAsTGv/E2U2+zs7PDw4UOkpKR8VnHD69xITKkUmDbtJL78cjWSklIBpF3Hpk2b8ixsiPIJHR1+VRLlBW3t99hzI6Hnz9+hS5edCA19AADYuvUWvv22isSpiIiICjYWNxI5ejQMnTvvQGTkOxgZ6WHRIn907lxZ6lhEREQFHvta85hCocTEicfRpMk6REa+Q4UKdrh0qS969PDiYSgiIolFRUWhWLFiePjwodRRCp2FCxeiVatWebIuFjd5LCjoICZNOgEhgJ49PXHxYh9ecZiItKp79+6QyWSQyWTQ09NDyZIlMWDAALx58ybDtGfPnoW/vz+srKxgaGiIypUrY86cOZle0+fYsWPw9/eHjY0NjI2NUaFCBYwYMQJPnz7Ni7eVJ2bMmIGWLVvC1dVV6ii5IiIiAp06dUK5cuWgo6ODYcOGZWu+x48fo2XLljAxMYGtrS2GDBmC5ORktWlu3LiB+vXrw8jICMWLF8fkyZMhhFC93qdPH1y8eBGnT5/W5lvKFIubPDZ0aE0UL26G339vg1Wrvoaxsb7UkYioEGrevDkiIiLw8OFDrFy5Env27MHAgQPVptm5cyfq168PZ2dnHDt2DP/++y+GDh2KadOmoUOHDmo7pmXLlqFJkyZwcHDA9u3bcevWLSxduhTR0dGYM2dOnr2vD3eo2pSQkIBVq1ahd+/en7Wc3Mz4uZKSkmBnZ4exY8eiatWq2ZpHoVCgRYsWiIuLw+nTp7F582Zs374dI0aMUE0TExODpk2bwsnJCRcvXsSvv/6K2bNnY+7cuappDAwM0KlTJ/z6669af18ZiCImOjpaABDR0dHaXXDyOyFmI+2R/E7VnJKiEIcO3VObNDExRbvrJqJckZCQIG7duiUSEhLSGpTKtM+3FA+lMtu5u3XrJr7++mu1tqCgIGFtba16/u7dO2FjYyPatm2bYf7du3cLAGLz5s1CCCHCw8OFXC4Xw4YNy3R9b968yTLLmzdvRJ8+fUSxYsWEgYGBqFixotizZ48QQogJEyaIqlWrqk0/b9484eLikuG9TJ8+XTg6OgoXFxcxevRoUaNGjQzrqly5shg/frzq+erVq4WHh4cwMDAQ5cqVE4sWLcoypxBCbN++Xdja2qq1paamip49ewpXV1dhaGgo3N3dRXBwsNo0mWUUQognT56IgIAAYWlpKaytrUWrVq1EWFiYar4LFy6IJk2aCBsbG2Fubi7q1asnLl++/NGM2lS/fn0xdOjQT063b98+oaOjI54+fapq27RpkzAwMFDtSxcvXiwsLCxEYmKiapoZM2YIJycnoXzvd/f48eNCLpeL+Pj4TNeV4TP3Hk323xxQnIuePIlBp07bcfr0Yxw48C18fUsDAAwMuNmJCqTUeGDB5105NceGvAP0TXI064MHD3DgwAHo6/+vp/jQoUOIiorCyJEjM0zfsmVLuLu7Y9OmTQgMDMTWrVuRnJyMUaNGZbp8S0vLTNuVSiX8/PwQGxuL9evXo3Tp0rh165bG1y85cuQIzM3NERoaqupNmjlzJu7fv4/SpdO+V2/evIkbN25g27ZtAIAVK1ZgwoQJWLhwIby8vHD16lX06dMHJiYm6NatW6brOXnyJHx8fDK8B2dnZ2zZsgW2trY4e/Ys+vbtC0dHRwQEBGSZMT4+Hg0bNkTdunVx8uRJ6OnpYerUqWjevDn+/vtvyOVyxMbGolu3bliwYAEAYM6cOfD398fdu3dhZpb5fQQ3bNiAfv36fXR7LVu2DJ07d87Gls2ec+fOoVKlSnByclK1NWvWDElJSbh8+TIaNmyIc+fOoX79+jAwMFCbZsyYMXj48CHc3NwAAD4+PkhJScGFCxdQv359rWX8kOR72cWLF2PWrFmIiIhAxYoVERwcjLp162Y5/YkTJxAUFISbN2/CyckJo0aNQv/+/fMwcfbs23cXXbvuRFRUAszM5IiLy7/dlERU+Pz5558wNTWFQqFAYmIiAKgdIrhzJ+2GvOXLl890fg8PD9U0d+/ehbm5ORwdNbsNzOHDh3HhwgXcvn0b7u7uAIBSpUpp/F5MTEywcuVKyOVyVVuVKlWwceNG/PTTTwDSdvpffPGFaj1TpkzBnDlz0LZtWwCAm5sbbt26hWXLlmVZ3Dx8+FBtBw6k3eto0qRJqudubm44e/YstmzZolbcfJhx9erV0NHRwcqVK1Uni6xZswaWlpY4fvw4fH190ahRI7V1LVu2DFZWVjhx4gS++uqrTDO2atUKNWrU+Oj2sre3/+jrmoqMjMywTCsrK8jlckRGRqqm+XCcUvo8kZGRquLGxMQElpaWePjwYeEtbkJCQjBs2DAsXrwYderUwbJly+Dn54dbt26hZMmSGaYPCwuDv78/+vTpg/Xr1+PMmTMYOHAg7Ozs0K5dOwneQUYpCh2MHX0Cs+ZeBABUq+aIkJD2KFPGWuJkRPTZ9IzTelCkWrcGGjZsiCVLliA+Ph4rV67EnTt38N1332WYTrw3rubD9vSd8vv/18S1a9fg7OysKjhyqnLlymqFDQB07twZq1evxk8//QQhBDZt2qQaHPvy5UuEh4ejV69e6NOnj2qe1NRUWFhYZLmehIQEGBoaZmhfunQpVq5ciUePHiEhIQHJycnw9PT8aMbLly/j3r17GXpgEhMTcf/+fQDAixcvMH78eBw9ehTPnz+HQqFAfHw8Hj9+nGVGMzOzLHt1clNmP/8Pfy8+nCb9d+vDdiMjo1y/V5ukxc3cuXPRq1cv1eCt4OBgHDx4EEuWLMGMGTMyTL906VKULFkSwcHBANL+4rh06RJmz56dL4qbR68t0GFDe5x/lFbYfPdddcya1ZSHoYgKC5ksx4eG8pqJiQnKlCkDAFiwYAEaNmyISZMmYcqUKQCgKjhu376N2rVrZ5j/33//RYUKFVTTRkdHIyIiQqPeGyMjo4++rqOjk6G4SklJyfS9fKhTp04YPXo0rly5goSEBISHh6NDhw4A0g4lAWmHpj7s5fjYITFbW9sMZ5Rt2bIFw4cPx5w5c1CrVi2YmZlh1qxZ+Ouvvz6aUalUwtvbGxs2bMiwHju7tDNku3fvjpcvXyI4OBguLi4wMDBArVq1PjogWYrDUg4ODhne75s3b5CSkqLqnXFwcFD14qR78eIFgIw9Sa9fv1Ztg9wi2V43OTkZly9fxujRo9XafX19cfbs2UznOXfuHHx9fdXamjVrhlWrViElJUXteHK6pKQkJCUlqZ7HxMRoIX3mToa54PyjErCwMMDq1V+jbdvMu3uJiPLahAkT4OfnhwEDBsDJyQm+vr6wtrbGnDlzMhQ3u3fvxt27d1WFUPv27TF69Gj88ssvmDdvXoZlv337NtNxN1WqVMGTJ09w586dTHtv7OzsEBkZqdYDcO3atWy9H2dnZ9SrVw8bNmxAQkICmjRpotqJ2tvbo3jx4njw4IFGO3kvLy+sX79ere3UqVOoXbu22plm6T0vH1OtWjWEhISgWLFiMDc3z3SaU6dOYfHixfD39wcAhIeH49WrVx9drhSHpWrVqoVp06apFbeHDh2CgYEBvL29VdP8+OOPSE5OVvVgHTp0CE5OTmqHq+7fv4/ExER4eXlpNWMGnxxynEuePn0qAIgzZ86otU+bNk24u7tnOk/ZsmXFtGnT1NrOnDkjAIhnz55lOs+ECRMEgAyP3Dpbarrfl+LBf0+0u2wiksTHztzIzzI7W0oIIby9vcWgQYNUz7du3Sp0dXVFnz59xPXr10VYWJhYuXKlsLKyEu3bt1c7y2XRokVCJpOJnj17iuPHj4uHDx+K06dPi759+4qgoKAsszRo0EBUqlRJHDp0SDx48EDs27dP7N+/XwghxK1bt4RMJhMzZ84U9+7dEwsXLhRWVlaZni2VmeXLlwsnJydha2srfv/9d7XXVqxYIYyMjERwcLD477//xN9//y1Wr14t5syZk2XWv//+W+jp6YnXr1+r2oKDg4W5ubk4cOCA+O+//8S4ceOEubm52llemWWMi4sTZcuWFQ0aNBAnT54UDx48EMePHxdDhgwR4eHhQgghPD09RdOmTcWtW7fE+fPnRd26dYWRkZGYN29elhm14erVq+Lq1avC29tbdOrUSVy9elXcvHlT9fqOHTtEuXLlVM9TU1NFpUqVROPGjcWVK1fE4cOHhbOzsxg8eLBqmrdv3wp7e3vRsWNHcePGDbFjxw5hbm4uZs+erbbuNWvWiFKlSmWZTVtnS0le3Jw9e1atferUqWob9X1ly5YV06dPV2s7ffq0ACAiIiIynScxMVFER0erHuHh4blT3Lx/iqgGp2wSUf5V2IqbDRs2CLlcLh4/fqxqO3nypGjevLmwsLAQcrlcVKhQQcyePVukpqZmmD80NFQ0a9ZMWFlZCUNDQ+Hh4SFGjhyZ5R+XQggRFRUlevToIWxsbIShoaGoVKmS+PPPP1WvL1myRJQoUUKYmJiIrl27imnTpmW7uHnz5o0wMDAQxsbGIjY2NtP36+npKeRyubCyshL16tUTO3bsyDKrEELUrFlTLF26VPU8MTFRdO/eXVhYWAhLS0sxYMAAMXr06E8WN0IIERERIbp27SpsbW2FgYGBKFWqlOjTp49q/3PlyhXh4+MjDAwMRNmyZcXWrVuFi4tLrhc3mf3B//42X7Nmjfiw7+PRo0eiRYsWwsjISFhbW4vBgwernfYtRFpxWLduXWFgYCAcHBzExIkT1QpkIYTw9fUVM2bMyDKbtoob2f+/0TyXnJwMY2NjbN26FW3atFG1Dx06FNeuXcOJEycyzFOvXj14eXlh/vz5qradO3ciICAA8fHxmR6W+lBMTAwsLCwQHR2dZVchERGQNvgzLCwMbm5umQ40pcJn3759GDlyJP755x/eDV7L/vnnHzRu3Bh37tzJcmD3xz5zmuy/JfvJyeVyeHt7IzQ0VK09NDQ008FtQNoxvQ+nP3ToEHx8fLJV2BAREX2Mv78/+vXrV6huKZFfPHv2DOvWrfvoGWvaIulpPEFBQejSpQt8fHxQq1YtLF++HI8fP1Zdt2bMmDF4+vQp1q1bBwDo378/Fi5ciKCgIPTp0wfnzp3DqlWrsGnTJinfBhERFSJDhw6VOkKh9OEJQblJ0uImMDAQUVFRmDx5MiIiIlCpUiXs27cPLi4uANJu8PX++f5ubm7Yt28fhg8fjkWLFsHJyQkLFizIF6eBExERUf4g2ZgbqXDMDRFlF8fcEOWtAj/mhoiooChifwMSSUZbnzUWN0REWUg/USG3LxVPRGnSr86s6c1VP8T7AhARZUFXVxeWlpaqy8gbGxvn6B5LRPRpSqUSL1++hLGxMfT0Pq88YXFDRPQRDg4OAP53nxwiyj06OjooWbLkZ/8RweKGiOgjZDIZHB0dUaxYsUxv6khE2iOXy7Vy8UQWN0RE2aCrq/vZ4wCIKG9wQDEREREVKixuiIiIqFBhcUNERESFSpEbc5N+gaCYmBiJkxAREVF2pe+3s3OhvyJX3MTGxgIASpQoIXESIiIi0lRsbOwn7yxe5O4tpVQq8ezZM5iZmWn9YlwxMTEoUaIEwsPDed+qXMTtnDe4nfMGt3Pe4bbOG7m1nYUQiI2NhZOT0ydPFy9yPTc6OjpwdnbO1XWYm5vzg5MHuJ3zBrdz3uB2zjvc1nkjN7bzp3ps0nFAMRERERUqLG6IiIioUGFxo0UGBgaYMGECDAwMpI5SqHE75w1u57zB7Zx3uK3zRn7YzkVuQDEREREVbuy5ISIiokKFxQ0REREVKixuiIiIqFBhcUNERESFCosbDS1evBhubm4wNDSEt7c3Tp069dHpT5w4AW9vbxgaGqJUqVJYunRpHiUt2DTZzjt27EDTpk1hZ2cHc3Nz1KpVCwcPHszDtAWXpr/P6c6cOQM9PT14enrmbsBCQtPtnJSUhLFjx8LFxQUGBgYoXbo0Vq9enUdpCy5Nt/OGDRtQtWpVGBsbw9HRET169EBUVFQepS2YTp48iZYtW8LJyQkymQy7du365DyS7AcFZdvmzZuFvr6+WLFihbh165YYOnSoMDExEY8ePcp0+gcPHghjY2MxdOhQcevWLbFixQqhr68vtm3blsfJCxZNt/PQoUPFzz//LC5cuCDu3LkjxowZI/T19cWVK1fyOHnBoul2Tvf27VtRqlQp4evrK6pWrZo3YQuwnGznVq1aiRo1aojQ0FARFhYm/vrrL3HmzJk8TF3waLqdT506JXR0dMT8+fPFgwcPxKlTp0TFihVF69at8zh5wbJv3z4xduxYsX37dgFA7Ny586PTS7UfZHGjgerVq4v+/furtXl4eIjRo0dnOv2oUaOEh4eHWlu/fv1EzZo1cy1jYaDpds5MhQoVxKRJk7QdrVDJ6XYODAwU48aNExMmTGBxkw2abuf9+/cLCwsLERUVlRfxCg1Nt/OsWbNEqVKl1NoWLFggnJ2dcy1jYZOd4kaq/SAPS2VTcnIyLl++DF9fX7V2X19fnD17NtN5zp07l2H6Zs2a4dKlS0hJScm1rAVZTrbzh5RKJWJjY2FtbZ0bEQuFnG7nNWvW4P79+5gwYUJuRywUcrKdd+/eDR8fH/zyyy8oXrw43N3dMXLkSCQkJORF5AIpJ9u5du3aePLkCfbt2wchBJ4/f45t27ahRYsWeRG5yJBqP1jkbpyZU69evYJCoYC9vb1au729PSIjIzOdJzIyMtPpU1NT8erVKzg6OuZa3oIqJ9v5Q3PmzEFcXBwCAgJyI2KhkJPtfPfuXYwePRqnTp2Cnh6/OrIjJ9v5wYMHOH36NAwNDbFz5068evUKAwcOxOvXrznuJgs52c61a9fGhg0bEBgYiMTERKSmpqJVq1b49ddf8yJykSHVfpA9NxqSyWRqz4UQGdo+NX1m7aRO0+2cbtOmTZg4cSJCQkJQrFix3IpXaGR3OysUCnTq1AmTJk2Cu7t7XsUrNDT5fVYqlZDJZNiwYQOqV68Of39/zJ07F2vXrmXvzSdosp1v3bqFIUOGYPz48bh8+TIOHDiAsLAw9O/fPy+iFilS7Af551c22draQldXN8NfAS9evMhQlaZzcHDIdHo9PT3Y2NjkWtaCLCfbOV1ISAh69eqFrVu3okmTJrkZs8DTdDvHxsbi0qVLuHr1KgYPHgwgbScshICenh4OHTqERo0a5Un2giQnv8+Ojo4oXrw4LCwsVG3ly5eHEAJPnjxB2bJlczVzQZST7TxjxgzUqVMH33//PQCgSpUqMDExQd26dTF16lT2rGuJVPtB9txkk1wuh7e3N0JDQ9XaQ0NDUbt27UznqVWrVobpDx06BB8fH+jr6+da1oIsJ9sZSOux6d69OzZu3Mhj5tmg6XY2NzfHjRs3cO3aNdWjf//+KFeuHK5du4YaNWrkVfQCJSe/z3Xq1MGzZ8/w7t07VdudO3ego6MDZ2fnXM1bUOVkO8fHx0NHR30XqKurC+B/PQv0+STbD+bqcOVCJv1Uw1WrVolbt26JYcOGCRMTE/Hw4UMhhBCjR48WXbp0UU2ffgrc8OHDxa1bt8SqVat4Kng2aLqdN27cKPT09MSiRYtERESE6vH27Vup3kKBoOl2/hDPlsoeTbdzbGyscHZ2Fu3btxc3b94UJ06cEGXLlhW9e/eW6i0UCJpu5zVr1gg9PT2xePFicf/+fXH69Gnh4+MjqlevLtVbKBBiY2PF1atXxdWrVwUAMXfuXHH16lXVKff5ZT/I4kZDixYtEi4uLkIul4tq1aqJEydOqF7r1q2bqF+/vtr0x48fF15eXkIulwtXV1exZMmSPE5cMGmynevXry8AZHh069Yt74MXMJr+Pr+PxU32abqdb9++LZo0aSKMjIyEs7OzCAoKEvHx8XmcuuDRdDsvWLBAVKhQQRgZGQlHR0fRuXNn8eTJkzxOXbAcO3bso9+3+WU/KBOC/W9ERERUeHDMDRERERUqLG6IiIioUGFxQ0RERIUKixsiIiIqVFjcEBERUaHC4oaIiIgKFRY3REREVKiwuCEiNWvXroWlpaXUMXLM1dUVwcHBH51m4sSJ8PT0zJM8RJT3WNwQFULdu3eHTCbL8Lh3757U0bB27Vq1TI6OjggICEBYWJhWln/x4kX07dtX9Vwmk2HXrl1q04wcORJHjhzRyvqy8uH7tLe3R8uWLXHz5k2Nl1OQi00iKbC4ISqkmjdvjoiICLWHm5ub1LEApN2IMyIiAs+ePcPGjRtx7do1tGrVCgqF4rOXbWdnB2Nj449OY2pqmqt3JE73/vvcu3cv4uLi0KJFCyQnJ+f6uomKMhY3RIWUgYEBHBwc1B66urqYO3cuKleuDBMTE5QoUQIDBw5UuwP1h65fv46GDRvCzMwM5ubm8Pb2xqVLl1Svnz17FvXq1YORkRFKlCiBIUOGIC4u7qPZZDIZHBwc4OjoiIYNG2LChAn4559/VD1LS5YsQenSpSGXy1GuXDn8/vvvavNPnDgRJUuWhIGBAZycnDBkyBDVa+8flnJ1dQUAtGnTBjKZTPX8/cNSBw8ehKGhId6+fau2jiFDhqB+/fpae58+Pj4YPnw4Hj16hP/++081zcd+HsePH0ePHj0QHR2t6gGaOHEiACA5ORmjRo1C8eLFYWJigho1auD48eMfzUNUVLC4ISpidHR0sGDBAvzzzz/47bffcPToUYwaNSrL6Tt37gxnZ2dcvHgRly9fxujRo6Gvrw8AuHHjBpo1a4a2bdvi77//RkhICE6fPo3BgwdrlMnIyAgAkJKSgp07d2Lo0KEYMWIE/vnnH/Tr1w89evTAsWPHAADbtm3DvHnzsGzZMty9exe7du1C5cqVM13uxYsXAQBr1qxBRESE6vn7mjRpAktLS2zfvl3VplAosGXLFnTu3Flr7/Pt27fYuHEjAKi2H/Dxn0ft2rURHBys6gGKiIjAyJEjAQA9evTAmTNnsHnzZvz999/45ptv0Lx5c9y9ezfbmYgKrVy/NScR5blu3boJXV1dYWJionq0b98+02m3bNkibGxsVM/XrFkjLCwsVM/NzMzE2rVrM523S5cuom/fvmptp06dEjo6OiIhISHTeT5cfnh4uKhZs6ZwdnYWSUlJonbt2qJPnz5q83zzzTfC399fCCHEnDlzhLu7u0hOTs50+S4uLmLevHmq5wDEzp071ab58I7mQ4YMEY0aNVI9P3jwoJDL5eL169ef9T4BCBMTE2FsbKy6e3KrVq0ynT7dp34eQghx7949IZPJxNOnT9XaGzduLMaMGfPR5RMVBXrSllZElFsaNmyIJUuWqJ6bmJgAAI4dO4bp06fj1q1biImJQWpqKhITExEXF6ea5n1BQUHo3bs3fv/9dzRp0gTffPMNSpcuDQC4fPky7t27hw0bNqimF0JAqVQiLCwM5cuXzzRbdHQ0TE1NIYRAfHw8qlWrhh07dkAul+P27dtqA4IBoE6dOpg/fz4A4JtvvkFwcDBKlSqF5s2bw9/fHy1btoSeXs6/zjp37oxatWrh2bNncHJywoYNG+Dv7w8rK6vPep9mZma4cuUKUlNTceLECcyaNQtLly5Vm0bTnwcAXLlyBUIIuLu7q7UnJSXlyVgiovyOxQ1RIWViYoIyZcqotT169Aj+/v7o378/pkyZAmtra5w+fRq9evVCSkpKpsuZOHEiOnXqhL1792L//v2YMGECNm/ejDZt2kCpVKJfv35qY17SlSxZMsts6Tt9HR0d2NvbZ9iJy2QytedCCFVbiRIl8N9//yE0NBSHDx/GwIEDMWvWLJw4cULtcI8mqlevjtKlS2Pz5s0YMGAAdu7ciTVr1qhez+n71NHRUf0MPDw8EBkZicDAQJw8eRJAzn4e6Xl0dXVx+fJl6Orqqr1mamqq0XsnKoxY3BAVIZcuXUJqairmzJkDHZ20IXdbtmz55Hzu7u5wd3fH8OHD0bFjR6xZswZt2rRBtWrVcPPmzQxF1Ke8v9P/UPny5XH69Gl07dpV1Xb27Fm13hEjIyO0atUKrVq1wqBBg+Dh4YEbN26gWrVqGZanr6+frbOwOnXqhA0bNsDZ2Rk6Ojpo0aKF6rWcvs8PDR8+HHPnzsXOnTvRpk2bbP085HJ5hvxeXl5QKBR48eIF6tat+1mZiAojDigmKkJKly6N1NRU/Prrr3jw4AF+//33DIdJ3peQkIDBgwfj+PHjePToEc6cOYOLFy+qCo0ffvgB586dw6BBg3Dt2jXcvXsXu3fvxnfffZfjjN9//z3Wrl2LpUuX4u7du5g7dy527NihGki7du1arFq1Cv/884/qPRgZGcHFxSXT5bm6uuLIkSOIjIzEmzdvslxv586dceXKFUybNg3t27eHoaGh6jVtvU9zc3P07t0bEyZMgBAiWz8PV1dXvHv3DkeOHMGrV68QHx8Pd3d3dO7cGV27dsWOHTsQFhaGixcv4ueff8a+ffs0ykRUKEk54IeIcke3bt3E119/nelrc+fOFY6OjsLIyEg0a9ZMrFu3TgAQb968EUKoD2BNSkoSHTp0ECVKlBByuVw4OTmJwYMHqw2ivXDhgmjatKkwNTUVJiYmokqVKmLatGlZZstsgOyHFi9eLEqVKiX09fWFu7u7WLduneq1nTt3iho1aghzc3NhYmIiatasKQ4fPqx6/cMBxbt37xZlypQRenp6wsXFRQiRcUBxui+++EIAEEePHs3wmrbe56NHj4Senp4ICQkRQnz65yGEEP379xc2NjYCgJgwYYIQQojk5GQxfvx44erqKvT19YWDg4No06aN+Pvvv7PMRFRUyIQQQtryioiIiEh7eFiKiIiIChUWN0RERFSosLghIiKiQoXFDRERERUqLG6IiIioUGFxQ0RERIUKixsiIiIqVFjcEBERUaHC4oaIiIgKFRY3REREVKiwuCEiIqJChcUNERERFSr/BwBpOrnd4jO+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, SeparableConv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ---------------- Data Augmentation Before Splitting ----------------\n",
    "\n",
    "# Map labels to binary classification: Feet = 1, Non-Feet = 0\n",
    "binary_labels = np.where(labels == 9, 1, 0)  # Event ID for Feet is 9\n",
    "\n",
    "# Separate Feet and Non-Feet data\n",
    "feet_features = features[binary_labels == 1]\n",
    "non_feet_features = features[binary_labels == 0]\n",
    "\n",
    "# Oversample Feet trials to balance the dataset\n",
    "n_feet = len(feet_features)\n",
    "n_non_feet = len(non_feet_features)\n",
    "oversampled_feet_features = np.tile(feet_features, (n_non_feet // n_feet, 1, 1))\n",
    "remainder = n_non_feet % n_feet\n",
    "if remainder > 0:\n",
    "    oversampled_feet_features = np.concatenate([oversampled_feet_features, feet_features[:remainder]], axis=0)\n",
    "\n",
    "# Combine the balanced dataset\n",
    "balanced_features = np.concatenate([oversampled_feet_features, non_feet_features], axis=0)\n",
    "balanced_labels = np.concatenate([np.ones(len(oversampled_feet_features)), np.zeros(n_non_feet)], axis=0)\n",
    "\n",
    "# Normalize the features (Z-score normalization)\n",
    "balanced_features = (balanced_features - np.mean(balanced_features, axis=0)) / np.std(balanced_features, axis=0)\n",
    "\n",
    "# Apply Gaussian noise for data augmentation\n",
    "noise_factor = 0.05\n",
    "augmented_features = balanced_features + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=balanced_features.shape)\n",
    "augmented_features = np.clip(augmented_features, -1.0, 1.0)  # Ensure valid range for EEG signals\n",
    "\n",
    "# Combine original and augmented data\n",
    "final_features = np.concatenate((balanced_features, augmented_features))\n",
    "final_labels = np.concatenate((balanced_labels, balanced_labels))\n",
    "\n",
    "# Shuffle the final dataset\n",
    "final_features, final_labels = shuffle(final_features, final_labels, random_state=42)\n",
    "\n",
    "# Split into training and testing sets (85% training, 15% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_features, final_labels, test_size=0.15, random_state=42)\n",
    "\n",
    "# Reshape data for CNN input\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing labels shape: {y_test.shape}\")\n",
    "\n",
    "# ---------------- Build the EEGNet Model ----------------\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Temporal Convolution Block\n",
    "model.add(Conv2D(8, kernel_size=(1, 64), padding='same', input_shape=(22, X_train.shape[2], 1),\n",
    "                 activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(DepthwiseConv2D(kernel_size=(22, 1), depth_multiplier=2, use_bias=False, activation='relu',\n",
    "                          depthwise_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))  # Increased dropout for regularization\n",
    "\n",
    "# Spatial Convolution Block\n",
    "model.add(SeparableConv2D(16, kernel_size=(1, 16), use_bias=False, padding='same', activation='relu',\n",
    "                          depthwise_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(1, 4)))\n",
    "model.add(Dropout(0.4))  # Increased dropout\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "# Compile the Model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ---------------- Training the Model ----------------\n",
    "\n",
    "# Callbacks for learning rate adjustment and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ---------------- Evaluate the Model ----------------\n",
    "\n",
    "# Test accuracy\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)  # Default threshold 0.5\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ---------------- Plot ROC Curve ----------------\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 135ms/step - accuracy: 0.5236 - loss: 1.9946 - val_accuracy: 0.5069 - val_loss: 1.5375 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 115ms/step - accuracy: 0.6200 - loss: 1.2088 - val_accuracy: 0.5944 - val_loss: 1.1091 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 112ms/step - accuracy: 0.6780 - loss: 0.9851 - val_accuracy: 0.7578 - val_loss: 0.9068 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 112ms/step - accuracy: 0.7438 - loss: 0.9399 - val_accuracy: 0.7910 - val_loss: 0.8961 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8073 - loss: 0.8854 - val_accuracy: 0.8619 - val_loss: 0.8138 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 71ms/step - accuracy: 0.8386 - loss: 0.8585 - val_accuracy: 0.8836 - val_loss: 0.7771 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 0.8606 - loss: 0.8039 - val_accuracy: 0.8952 - val_loss: 0.7505 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 98ms/step - accuracy: 0.8758 - loss: 0.8000 - val_accuracy: 0.9234 - val_loss: 0.7242 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.8863 - loss: 0.8023 - val_accuracy: 0.9364 - val_loss: 0.7238 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 94ms/step - accuracy: 0.8832 - loss: 0.8034 - val_accuracy: 0.9212 - val_loss: 0.7515 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 0.8850 - loss: 0.8073 - val_accuracy: 0.9291 - val_loss: 0.7024 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 100ms/step - accuracy: 0.9002 - loss: 0.7612 - val_accuracy: 0.8937 - val_loss: 0.7695 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 101ms/step - accuracy: 0.8896 - loss: 0.7773 - val_accuracy: 0.9487 - val_loss: 0.7012 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 101ms/step - accuracy: 0.8928 - loss: 0.7789 - val_accuracy: 0.9465 - val_loss: 0.6897 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.8964 - loss: 0.7773 - val_accuracy: 0.9422 - val_loss: 0.7032 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.9067 - loss: 0.7779 - val_accuracy: 0.9443 - val_loss: 0.7001 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.9120 - loss: 0.7557 - val_accuracy: 0.9161 - val_loss: 0.7445 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 0.9001 - loss: 0.7703 - val_accuracy: 0.9523 - val_loss: 0.6904 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 0.8995 - loss: 0.7821 - val_accuracy: 0.9682 - val_loss: 0.6590 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.9034 - loss: 0.7736 - val_accuracy: 0.9313 - val_loss: 0.7498 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - accuracy: 0.9026 - loss: 0.7915 - val_accuracy: 0.9364 - val_loss: 0.7180 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.9164 - loss: 0.7382 - val_accuracy: 0.9516 - val_loss: 0.6895 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 101ms/step - accuracy: 0.9051 - loss: 0.7733 - val_accuracy: 0.9581 - val_loss: 0.7014 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9084 - loss: 0.7943\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 98ms/step - accuracy: 0.9084 - loss: 0.7942 - val_accuracy: 0.9537 - val_loss: 0.6827 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 0.9351 - loss: 0.7064 - val_accuracy: 0.9747 - val_loss: 0.5567 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 0.9522 - loss: 0.5800 - val_accuracy: 0.9826 - val_loss: 0.4639 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.9478 - loss: 0.5165 - val_accuracy: 0.9740 - val_loss: 0.4294 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 0.9550 - loss: 0.4657 - val_accuracy: 0.9826 - val_loss: 0.4045 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.9492 - loss: 0.4692 - val_accuracy: 0.9798 - val_loss: 0.3898 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 95ms/step - accuracy: 0.9554 - loss: 0.4338 - val_accuracy: 0.9798 - val_loss: 0.3878 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.9516 - loss: 0.4310 - val_accuracy: 0.9769 - val_loss: 0.3854 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.9430 - loss: 0.4590 - val_accuracy: 0.9769 - val_loss: 0.3945 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.9546 - loss: 0.4485 - val_accuracy: 0.9711 - val_loss: 0.4072 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 103ms/step - accuracy: 0.9538 - loss: 0.4476 - val_accuracy: 0.9841 - val_loss: 0.3943 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 107ms/step - accuracy: 0.9424 - loss: 0.4653 - val_accuracy: 0.9675 - val_loss: 0.4238 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9504 - loss: 0.4498\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 107ms/step - accuracy: 0.9504 - loss: 0.4498 - val_accuracy: 0.9740 - val_loss: 0.4019 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 108ms/step - accuracy: 0.9570 - loss: 0.4282 - val_accuracy: 0.9841 - val_loss: 0.3532 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.9646 - loss: 0.3893 - val_accuracy: 0.9892 - val_loss: 0.3291 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.9660 - loss: 0.3618 - val_accuracy: 0.9848 - val_loss: 0.3089 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 101ms/step - accuracy: 0.9692 - loss: 0.3412 - val_accuracy: 0.9848 - val_loss: 0.2943 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.9769 - loss: 0.3092 - val_accuracy: 0.9863 - val_loss: 0.2815 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - accuracy: 0.9719 - loss: 0.3002 - val_accuracy: 0.9834 - val_loss: 0.2683 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 90ms/step - accuracy: 0.9757 - loss: 0.2787 - val_accuracy: 0.9870 - val_loss: 0.2559 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.9697 - loss: 0.2864 - val_accuracy: 0.9819 - val_loss: 0.2578 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 95ms/step - accuracy: 0.9767 - loss: 0.2726 - val_accuracy: 0.9848 - val_loss: 0.2502 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 94ms/step - accuracy: 0.9701 - loss: 0.2731 - val_accuracy: 0.9798 - val_loss: 0.2663 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9680 - loss: 0.2727 - val_accuracy: 0.9798 - val_loss: 0.2492 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9702 - loss: 0.2707 - val_accuracy: 0.9848 - val_loss: 0.2421 - learning_rate: 2.5000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9698 - loss: 0.2712 - val_accuracy: 0.9877 - val_loss: 0.2228 - learning_rate: 2.5000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.9759 - loss: 0.2522 - val_accuracy: 0.9892 - val_loss: 0.2341 - learning_rate: 2.5000e-04\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "Fold 1 Accuracy: 0.9877, ROC-AUC: 0.9996\n",
      "Confusion Matrix:\n",
      "[[675  17]\n",
      " [  0 691]]\n",
      "\n",
      "Training Fold 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 96ms/step - accuracy: 0.5098 - loss: 1.9715 - val_accuracy: 0.5127 - val_loss: 1.3597 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.5534 - loss: 1.2078 - val_accuracy: 0.6255 - val_loss: 0.9911 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 90ms/step - accuracy: 0.6088 - loss: 0.9610 - val_accuracy: 0.6725 - val_loss: 0.9278 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.7060 - loss: 0.8995 - val_accuracy: 0.7542 - val_loss: 0.8745 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.7840 - loss: 0.8604 - val_accuracy: 0.7643 - val_loss: 0.9423 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 95ms/step - accuracy: 0.8039 - loss: 0.8752 - val_accuracy: 0.8590 - val_loss: 0.7846 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.8422 - loss: 0.8168 - val_accuracy: 0.8554 - val_loss: 0.8412 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 82ms/step - accuracy: 0.8544 - loss: 0.8339 - val_accuracy: 0.8510 - val_loss: 0.8699 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.8545 - loss: 0.8334 - val_accuracy: 0.8727 - val_loss: 0.8355 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 94ms/step - accuracy: 0.8676 - loss: 0.8210 - val_accuracy: 0.8727 - val_loss: 0.8022 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.8814 - loss: 0.7852 - val_accuracy: 0.9002 - val_loss: 0.7483 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 98ms/step - accuracy: 0.8845 - loss: 0.7810 - val_accuracy: 0.9241 - val_loss: 0.7334 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 0.8909 - loss: 0.7833 - val_accuracy: 0.8604 - val_loss: 0.8578 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.8885 - loss: 0.7836 - val_accuracy: 0.8908 - val_loss: 0.8100 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 98ms/step - accuracy: 0.8937 - loss: 0.7993 - val_accuracy: 0.9168 - val_loss: 0.7695 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8896 - loss: 0.8109 - val_accuracy: 0.9205 - val_loss: 0.7512 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8903 - loss: 0.8088\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.8903 - loss: 0.8089 - val_accuracy: 0.8901 - val_loss: 0.8151 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.9125 - loss: 0.7485 - val_accuracy: 0.9436 - val_loss: 0.6218 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 95ms/step - accuracy: 0.9339 - loss: 0.6156 - val_accuracy: 0.9487 - val_loss: 0.5482 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.9458 - loss: 0.5345 - val_accuracy: 0.9472 - val_loss: 0.5084 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 94ms/step - accuracy: 0.9437 - loss: 0.4952 - val_accuracy: 0.9588 - val_loss: 0.4600 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.9414 - loss: 0.4810 - val_accuracy: 0.9342 - val_loss: 0.4913 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9385 - loss: 0.4751 - val_accuracy: 0.9581 - val_loss: 0.4418 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9419 - loss: 0.4737 - val_accuracy: 0.9385 - val_loss: 0.4873 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9374 - loss: 0.4782 - val_accuracy: 0.9458 - val_loss: 0.4645 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9366 - loss: 0.4714 - val_accuracy: 0.9537 - val_loss: 0.4484 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9327 - loss: 0.4783 - val_accuracy: 0.9667 - val_loss: 0.4235 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9507 - loss: 0.4591 - val_accuracy: 0.9465 - val_loss: 0.4786 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.9459 - loss: 0.4590 - val_accuracy: 0.9501 - val_loss: 0.4584 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9378 - loss: 0.4664 - val_accuracy: 0.9530 - val_loss: 0.4661 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.9457 - loss: 0.4719 - val_accuracy: 0.9537 - val_loss: 0.4575 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9379 - loss: 0.4828\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 94ms/step - accuracy: 0.9379 - loss: 0.4828 - val_accuracy: 0.9523 - val_loss: 0.4615 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 95ms/step - accuracy: 0.9465 - loss: 0.4690 - val_accuracy: 0.9624 - val_loss: 0.4130 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.9615 - loss: 0.4134 - val_accuracy: 0.9617 - val_loss: 0.3922 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 103ms/step - accuracy: 0.9628 - loss: 0.3834 - val_accuracy: 0.9638 - val_loss: 0.3653 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 112ms/step - accuracy: 0.9664 - loss: 0.3557 - val_accuracy: 0.9689 - val_loss: 0.3412 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 112ms/step - accuracy: 0.9673 - loss: 0.3377 - val_accuracy: 0.9675 - val_loss: 0.3235 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - accuracy: 0.9711 - loss: 0.3223 - val_accuracy: 0.9675 - val_loss: 0.3262 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 114ms/step - accuracy: 0.9682 - loss: 0.3122 - val_accuracy: 0.9646 - val_loss: 0.3205 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - accuracy: 0.9661 - loss: 0.3130 - val_accuracy: 0.9747 - val_loss: 0.2843 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 119ms/step - accuracy: 0.9643 - loss: 0.3028 - val_accuracy: 0.9732 - val_loss: 0.2807 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - accuracy: 0.9715 - loss: 0.2874 - val_accuracy: 0.9696 - val_loss: 0.2869 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 117ms/step - accuracy: 0.9611 - loss: 0.2994 - val_accuracy: 0.9646 - val_loss: 0.2885 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - accuracy: 0.9683 - loss: 0.2845 - val_accuracy: 0.9740 - val_loss: 0.2760 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - accuracy: 0.9670 - loss: 0.2854 - val_accuracy: 0.9798 - val_loss: 0.2653 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 121ms/step - accuracy: 0.9707 - loss: 0.2757 - val_accuracy: 0.9631 - val_loss: 0.2929 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 120ms/step - accuracy: 0.9707 - loss: 0.2721 - val_accuracy: 0.9732 - val_loss: 0.2693 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 128ms/step - accuracy: 0.9747 - loss: 0.2627 - val_accuracy: 0.9696 - val_loss: 0.2886 - learning_rate: 2.5000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 115ms/step - accuracy: 0.9684 - loss: 0.2708 - val_accuracy: 0.9754 - val_loss: 0.2662 - learning_rate: 2.5000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9638 - loss: 0.2813\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.9638 - loss: 0.2813 - val_accuracy: 0.9776 - val_loss: 0.2693 - learning_rate: 2.5000e-04\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "Fold 2 Accuracy: 0.9798, ROC-AUC: 0.9980\n",
      "Confusion Matrix:\n",
      "[[663  28]\n",
      " [  0 692]]\n",
      "\n",
      "Training Fold 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 125ms/step - accuracy: 0.5094 - loss: 1.9788 - val_accuracy: 0.5022 - val_loss: 2.0627 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 108ms/step - accuracy: 0.5919 - loss: 1.2001 - val_accuracy: 0.5405 - val_loss: 1.2262 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 108ms/step - accuracy: 0.6580 - loss: 0.9942 - val_accuracy: 0.7026 - val_loss: 0.9467 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7318 - loss: 0.9324 - val_accuracy: 0.7880 - val_loss: 0.8984 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7919 - loss: 0.9009 - val_accuracy: 0.7699 - val_loss: 0.9533 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8072 - loss: 0.9213 - val_accuracy: 0.8806 - val_loss: 0.8358 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 103ms/step - accuracy: 0.8602 - loss: 0.8577 - val_accuracy: 0.8495 - val_loss: 0.8814 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8589 - loss: 0.8769 - val_accuracy: 0.8538 - val_loss: 0.8813 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 182ms/step - accuracy: 0.8679 - loss: 0.8609 - val_accuracy: 0.9175 - val_loss: 0.7771 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 351ms/step - accuracy: 0.8793 - loss: 0.8447 - val_accuracy: 0.8994 - val_loss: 0.8098 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 355ms/step - accuracy: 0.8828 - loss: 0.8403 - val_accuracy: 0.9190 - val_loss: 0.7854 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 420ms/step - accuracy: 0.8947 - loss: 0.8354 - val_accuracy: 0.9088 - val_loss: 0.7928 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 347ms/step - accuracy: 0.8955 - loss: 0.8241 - val_accuracy: 0.9407 - val_loss: 0.7458 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 229ms/step - accuracy: 0.8971 - loss: 0.8183 - val_accuracy: 0.9096 - val_loss: 0.8022 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9011 - loss: 0.8024 - val_accuracy: 0.9385 - val_loss: 0.7449 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.8993 - loss: 0.8100 - val_accuracy: 0.9081 - val_loss: 0.8013 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.8959 - loss: 0.8312 - val_accuracy: 0.9493 - val_loss: 0.7257 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9104 - loss: 0.8026 - val_accuracy: 0.9320 - val_loss: 0.7625 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.8895 - loss: 0.8495 - val_accuracy: 0.9399 - val_loss: 0.7399 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9015 - loss: 0.8131 - val_accuracy: 0.9457 - val_loss: 0.7615 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step - accuracy: 0.8987 - loss: 0.8378 - val_accuracy: 0.9313 - val_loss: 0.7828 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9001 - loss: 0.8075\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9001 - loss: 0.8075 - val_accuracy: 0.9407 - val_loss: 0.7576 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9219 - loss: 0.7483 - val_accuracy: 0.9595 - val_loss: 0.6176 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.9355 - loss: 0.6389 - val_accuracy: 0.9559 - val_loss: 0.5666 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9431 - loss: 0.5574 - val_accuracy: 0.9421 - val_loss: 0.5478 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.9548 - loss: 0.4961 - val_accuracy: 0.9508 - val_loss: 0.4820 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9508 - loss: 0.4819 - val_accuracy: 0.9674 - val_loss: 0.4512 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step - accuracy: 0.9373 - loss: 0.4928 - val_accuracy: 0.9616 - val_loss: 0.4460 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9513 - loss: 0.4621 - val_accuracy: 0.9284 - val_loss: 0.5070 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.9534 - loss: 0.4579 - val_accuracy: 0.9559 - val_loss: 0.4650 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9492 - loss: 0.4643 - val_accuracy: 0.9508 - val_loss: 0.4644 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9388 - loss: 0.4597 - val_accuracy: 0.9508 - val_loss: 0.4637 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9484 - loss: 0.4820 - val_accuracy: 0.9624 - val_loss: 0.4354 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9421 - loss: 0.4850 - val_accuracy: 0.9674 - val_loss: 0.4422 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - accuracy: 0.9469 - loss: 0.4787 - val_accuracy: 0.9559 - val_loss: 0.4629 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - accuracy: 0.9484 - loss: 0.4803 - val_accuracy: 0.9725 - val_loss: 0.4310 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 94ms/step - accuracy: 0.9477 - loss: 0.4667 - val_accuracy: 0.9660 - val_loss: 0.4338 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 82ms/step - accuracy: 0.9504 - loss: 0.4629 - val_accuracy: 0.9689 - val_loss: 0.4366 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.9554 - loss: 0.4558 - val_accuracy: 0.9363 - val_loss: 0.5030 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.9443 - loss: 0.4762 - val_accuracy: 0.9616 - val_loss: 0.4472 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9477 - loss: 0.4730\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.9477 - loss: 0.4731 - val_accuracy: 0.9616 - val_loss: 0.4695 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - accuracy: 0.9516 - loss: 0.4592 - val_accuracy: 0.9689 - val_loss: 0.4246 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.9603 - loss: 0.4244 - val_accuracy: 0.9754 - val_loss: 0.3820 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - accuracy: 0.9626 - loss: 0.3923 - val_accuracy: 0.9703 - val_loss: 0.3728 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.9709 - loss: 0.3504 - val_accuracy: 0.9638 - val_loss: 0.3589 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.9737 - loss: 0.3368 - val_accuracy: 0.9624 - val_loss: 0.3421 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9715 - loss: 0.3282 - val_accuracy: 0.9703 - val_loss: 0.3154 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 101ms/step - accuracy: 0.9734 - loss: 0.3065 - val_accuracy: 0.9725 - val_loss: 0.3084 - learning_rate: 2.5000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9793 - loss: 0.2861 - val_accuracy: 0.9631 - val_loss: 0.3111 - learning_rate: 2.5000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9738 - loss: 0.2873 - val_accuracy: 0.9631 - val_loss: 0.3087 - learning_rate: 2.5000e-04\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "Fold 3 Accuracy: 0.9725, ROC-AUC: 0.9976\n",
      "Confusion Matrix:\n",
      "[[653  38]\n",
      " [  0 691]]\n",
      "\n",
      "Training Fold 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 90ms/step - accuracy: 0.5154 - loss: 2.0241 - val_accuracy: 0.5007 - val_loss: 1.3945 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.6156 - loss: 1.2042 - val_accuracy: 0.5941 - val_loss: 1.0957 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.6906 - loss: 0.9586 - val_accuracy: 0.7287 - val_loss: 0.8698 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.7516 - loss: 0.8514 - val_accuracy: 0.8394 - val_loss: 0.7567 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.8105 - loss: 0.8150 - val_accuracy: 0.8495 - val_loss: 0.7666 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.8241 - loss: 0.8153 - val_accuracy: 0.8799 - val_loss: 0.7483 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.8316 - loss: 0.8204 - val_accuracy: 0.8835 - val_loss: 0.7660 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.8625 - loss: 0.7942 - val_accuracy: 0.9038 - val_loss: 0.7388 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.8729 - loss: 0.7992 - val_accuracy: 0.9124 - val_loss: 0.7298 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8802 - loss: 0.7756 - val_accuracy: 0.8994 - val_loss: 0.7744 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8784 - loss: 0.7854 - val_accuracy: 0.9493 - val_loss: 0.6990 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8798 - loss: 0.7962 - val_accuracy: 0.9465 - val_loss: 0.6705 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.8968 - loss: 0.7369 - val_accuracy: 0.9247 - val_loss: 0.6895 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.8968 - loss: 0.7612 - val_accuracy: 0.9450 - val_loss: 0.6748 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.8913 - loss: 0.7697 - val_accuracy: 0.9399 - val_loss: 0.6711 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.8831 - loss: 0.7709 - val_accuracy: 0.9110 - val_loss: 0.7591 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m172/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8891 - loss: 0.7853\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.8892 - loss: 0.7853 - val_accuracy: 0.9407 - val_loss: 0.6860 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9112 - loss: 0.7188 - val_accuracy: 0.9580 - val_loss: 0.5676 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9346 - loss: 0.5977 - val_accuracy: 0.9595 - val_loss: 0.5007 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9328 - loss: 0.5347 - val_accuracy: 0.9631 - val_loss: 0.4504 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9468 - loss: 0.4949 - val_accuracy: 0.9479 - val_loss: 0.4568 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9420 - loss: 0.4690 - val_accuracy: 0.9682 - val_loss: 0.4181 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9542 - loss: 0.4425 - val_accuracy: 0.9580 - val_loss: 0.4108 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9394 - loss: 0.4609 - val_accuracy: 0.9711 - val_loss: 0.4002 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9428 - loss: 0.4489 - val_accuracy: 0.9703 - val_loss: 0.4015 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9457 - loss: 0.4533 - val_accuracy: 0.9457 - val_loss: 0.4500 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9388 - loss: 0.4609 - val_accuracy: 0.9616 - val_loss: 0.4174 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9390 - loss: 0.4679 - val_accuracy: 0.9711 - val_loss: 0.4052 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m172/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9453 - loss: 0.4544\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9452 - loss: 0.4545 - val_accuracy: 0.9682 - val_loss: 0.4108 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9524 - loss: 0.4424 - val_accuracy: 0.9674 - val_loss: 0.4031 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9597 - loss: 0.3997 - val_accuracy: 0.9631 - val_loss: 0.3745 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9674 - loss: 0.3685 - val_accuracy: 0.9747 - val_loss: 0.3324 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9670 - loss: 0.3530 - val_accuracy: 0.9725 - val_loss: 0.3202 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9689 - loss: 0.3199 - val_accuracy: 0.9768 - val_loss: 0.2960 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9747 - loss: 0.3020 - val_accuracy: 0.9718 - val_loss: 0.2982 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9707 - loss: 0.3014 - val_accuracy: 0.9682 - val_loss: 0.2959 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9703 - loss: 0.2930 - val_accuracy: 0.9783 - val_loss: 0.2730 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9732 - loss: 0.2794 - val_accuracy: 0.9631 - val_loss: 0.2895 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9673 - loss: 0.2840 - val_accuracy: 0.9776 - val_loss: 0.2617 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9730 - loss: 0.2705 - val_accuracy: 0.9747 - val_loss: 0.2676 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9684 - loss: 0.2742 - val_accuracy: 0.9805 - val_loss: 0.2456 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.9636 - loss: 0.2826 - val_accuracy: 0.9732 - val_loss: 0.2651 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9674 - loss: 0.2721 - val_accuracy: 0.9768 - val_loss: 0.2549 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9691 - loss: 0.2756 - val_accuracy: 0.9725 - val_loss: 0.2594 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9676 - loss: 0.2705 - val_accuracy: 0.9740 - val_loss: 0.2568 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9677 - loss: 0.2775\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9677 - loss: 0.2775 - val_accuracy: 0.9790 - val_loss: 0.2532 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9646 - loss: 0.2728 - val_accuracy: 0.9761 - val_loss: 0.2485 - learning_rate: 1.2500e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9733 - loss: 0.2548 - val_accuracy: 0.9754 - val_loss: 0.2440 - learning_rate: 1.2500e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9813 - loss: 0.2342 - val_accuracy: 0.9797 - val_loss: 0.2291 - learning_rate: 1.2500e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9792 - loss: 0.2340 - val_accuracy: 0.9797 - val_loss: 0.2226 - learning_rate: 1.2500e-04\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Fold 4 Accuracy: 0.9797, ROC-AUC: 0.9994\n",
      "Confusion Matrix:\n",
      "[[663  28]\n",
      " [  0 691]]\n",
      "\n",
      "Training Fold 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5083 - loss: 2.0444 - val_accuracy: 0.5007 - val_loss: 1.6005 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.5580 - loss: 1.1998 - val_accuracy: 0.5311 - val_loss: 1.2182 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.6342 - loss: 0.9946 - val_accuracy: 0.6635 - val_loss: 1.0285 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.7025 - loss: 0.9713 - val_accuracy: 0.7779 - val_loss: 0.9039 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.7770 - loss: 0.9210 - val_accuracy: 0.8676 - val_loss: 0.8235 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8243 - loss: 0.9001 - val_accuracy: 0.8886 - val_loss: 0.7964 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8476 - loss: 0.8545 - val_accuracy: 0.8864 - val_loss: 0.7917 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8719 - loss: 0.8301 - val_accuracy: 0.9313 - val_loss: 0.7350 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8793 - loss: 0.8237 - val_accuracy: 0.9161 - val_loss: 0.7401 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8872 - loss: 0.7858 - val_accuracy: 0.9342 - val_loss: 0.7117 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8899 - loss: 0.7688 - val_accuracy: 0.9472 - val_loss: 0.6998 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8931 - loss: 0.7876 - val_accuracy: 0.9226 - val_loss: 0.7276 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8990 - loss: 0.7720 - val_accuracy: 0.9421 - val_loss: 0.7096 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9046 - loss: 0.7831 - val_accuracy: 0.9551 - val_loss: 0.6852 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.8973 - loss: 0.7987 - val_accuracy: 0.9544 - val_loss: 0.7114 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.8968 - loss: 0.7877 - val_accuracy: 0.9262 - val_loss: 0.7244 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9090 - loss: 0.7535 - val_accuracy: 0.9580 - val_loss: 0.6776 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9025 - loss: 0.7870 - val_accuracy: 0.9479 - val_loss: 0.7152 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.9161 - loss: 0.7779 - val_accuracy: 0.9443 - val_loss: 0.7100 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9178 - loss: 0.7594 - val_accuracy: 0.9486 - val_loss: 0.6988 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9049 - loss: 0.7909 - val_accuracy: 0.9349 - val_loss: 0.7098 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9170 - loss: 0.7456 - val_accuracy: 0.9573 - val_loss: 0.6701 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9108 - loss: 0.7550 - val_accuracy: 0.9385 - val_loss: 0.6985 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9119 - loss: 0.7262 - val_accuracy: 0.9522 - val_loss: 0.6662 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9137 - loss: 0.7619 - val_accuracy: 0.9255 - val_loss: 0.7427 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9283 - loss: 0.7233 - val_accuracy: 0.9276 - val_loss: 0.7317 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9120 - loss: 0.7559 - val_accuracy: 0.9595 - val_loss: 0.6422 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9117 - loss: 0.7507 - val_accuracy: 0.9522 - val_loss: 0.6878 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9176 - loss: 0.7723 - val_accuracy: 0.9508 - val_loss: 0.6968 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9142 - loss: 0.7432 - val_accuracy: 0.9428 - val_loss: 0.6810 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9236 - loss: 0.7327 - val_accuracy: 0.9530 - val_loss: 0.6593 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m172/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9179 - loss: 0.7427\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9178 - loss: 0.7429 - val_accuracy: 0.9522 - val_loss: 0.6780 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9283 - loss: 0.7066 - val_accuracy: 0.9638 - val_loss: 0.5693 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9449 - loss: 0.5917 - val_accuracy: 0.9725 - val_loss: 0.4833 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9516 - loss: 0.5193 - val_accuracy: 0.9667 - val_loss: 0.4497 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9492 - loss: 0.4759 - val_accuracy: 0.9732 - val_loss: 0.4206 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9513 - loss: 0.4556 - val_accuracy: 0.9725 - val_loss: 0.3933 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9558 - loss: 0.4326 - val_accuracy: 0.9689 - val_loss: 0.4055 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9568 - loss: 0.4269 - val_accuracy: 0.9740 - val_loss: 0.3827 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9553 - loss: 0.4244 - val_accuracy: 0.9703 - val_loss: 0.3932 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9572 - loss: 0.4259 - val_accuracy: 0.9783 - val_loss: 0.3753 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9470 - loss: 0.4391 - val_accuracy: 0.9747 - val_loss: 0.3940 - learning_rate: 5.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9504 - loss: 0.4319 - val_accuracy: 0.9761 - val_loss: 0.3903 - learning_rate: 5.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9548 - loss: 0.4280 - val_accuracy: 0.9631 - val_loss: 0.4299 - learning_rate: 5.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9526 - loss: 0.4391 - val_accuracy: 0.9754 - val_loss: 0.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9535 - loss: 0.4412 - val_accuracy: 0.9855 - val_loss: 0.3653 - learning_rate: 5.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9524 - loss: 0.4353 - val_accuracy: 0.9718 - val_loss: 0.4024 - learning_rate: 5.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9535 - loss: 0.4415 - val_accuracy: 0.9711 - val_loss: 0.4004 - learning_rate: 5.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9516 - loss: 0.4422 - val_accuracy: 0.9740 - val_loss: 0.3965 - learning_rate: 5.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9563 - loss: 0.4412 - val_accuracy: 0.9761 - val_loss: 0.3971 - learning_rate: 5.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Fold 5 Accuracy: 0.9855, ROC-AUC: 0.9991\n",
      "Confusion Matrix:\n",
      "[[675  16]\n",
      " [  4 687]]\n",
      "\n",
      "Cross-Validation Results:\n",
      "Mean Accuracy: 0.9810 ± 0.0053\n",
      "Mean ROC-AUC: 0.9987 ± 0.0008\n",
      "\n",
      "Confusion Matrix for Fold 1:\n",
      "[[675  17]\n",
      " [  0 691]]\n",
      "\n",
      "Confusion Matrix for Fold 2:\n",
      "[[663  28]\n",
      " [  0 692]]\n",
      "\n",
      "Confusion Matrix for Fold 3:\n",
      "[[653  38]\n",
      " [  0 691]]\n",
      "\n",
      "Confusion Matrix for Fold 4:\n",
      "[[663  28]\n",
      " [  0 691]]\n",
      "\n",
      "Confusion Matrix for Fold 5:\n",
      "[[675  16]\n",
      " [  4 687]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Arrays to store performance metrics for each fold\n",
    "accuracies = []\n",
    "roc_aucs = []\n",
    "confusion_matrices = []\n",
    "\n",
    "fold = 1\n",
    "for train_index, val_index in skf.split(final_features, final_labels):\n",
    "    print(f\"\\nTraining Fold {fold}/{n_splits}...\")\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val = final_features[train_index], final_features[val_index]\n",
    "    y_train, y_val = final_labels[train_index], final_labels[val_index]\n",
    "    \n",
    "    # Reshape data for CNN input\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_val = X_val[..., np.newaxis]\n",
    "    \n",
    "    # Build the EEGNet model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, kernel_size=(1, 64), padding='same', input_shape=(22, X_train.shape[2], 1),\n",
    "                     activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(22, 1), depth_multiplier=2, use_bias=False, activation='relu',\n",
    "                              depthwise_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(SeparableConv2D(16, kernel_size=(1, 16), use_bias=False, padding='same', activation='relu',\n",
    "                              depthwise_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(1, 4)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Callbacks\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[reduce_lr, early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    y_val_pred_probs = model.predict(X_val)\n",
    "    y_val_pred = (y_val_pred_probs > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_val_pred_probs)\n",
    "    confusion = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # Store metrics\n",
    "    accuracies.append(accuracy)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    confusion_matrices.append(confusion)\n",
    "    \n",
    "    # Print fold-specific results\n",
    "    print(f\"Fold {fold} Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# Aggregate metrics\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "mean_roc_auc = np.mean(roc_aucs)\n",
    "std_roc_auc = np.std(roc_aucs)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy:.4f}\")  # Added explicit standard deviation\n",
    "print(f\"Mean ROC-AUC: {mean_roc_auc:.4f} ± {std_roc_auc:.4f}\")\n",
    "print(f\"Standard Deviation of ROC-AUC: {std_roc_auc:.4f}\")    # Added explicit standard deviation\n",
    "\n",
    "# Display all confusion matrices\n",
    "for i, cm in enumerate(confusion_matrices, 1):\n",
    "    print(f\"\\nConfusion Matrix for Fold {i}:\")\n",
    "    print(cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
