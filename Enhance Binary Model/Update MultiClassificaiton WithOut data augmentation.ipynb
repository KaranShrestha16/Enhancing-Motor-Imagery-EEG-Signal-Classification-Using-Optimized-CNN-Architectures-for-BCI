{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, DepthwiseConv2D, SeparableConv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregularizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m l2\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Importing Required Libraries\n",
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, SeparableConv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# ------------------- Data Loading and Preprocessing -------------------\n",
    "\n",
    "# Base path for EEG data files (update this path to your dataset location)\n",
    "base_path = r'C:\\\\Users\\\\mango\\\\Downloads\\\\EEG Moter Imagary Datasets\\\\BCICIV_2a_gdf'\n",
    "subjects = [f'A0{i}' for i in range(1, 10) if i != 4]  # Exclude Subject 4\n",
    "event_ids = [7, 8, 9, 10]  # Event IDs: Right Hand, Left Hand, Feet, Tongue\n",
    "\n",
    "# Initialize lists for features and labels\n",
    "all_features, all_labels = [], []\n",
    "\n",
    "# Load data for each subject\n",
    "for subject in subjects:\n",
    "    file_path = f'{base_path}/{subject}T.gdf'\n",
    "    raw = mne.io.read_raw_gdf(file_path, preload=True)\n",
    "    raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])  # Drop non-EEG channels\n",
    "    raw.set_eeg_reference()  # Apply average referencing\n",
    "    raw.filter(8., 30., fir_design='firwin', verbose=False)  # Bandpass filter (8â€“30 Hz)\n",
    "\n",
    "    # Apply ICA for artifact removal\n",
    "    ica = mne.preprocessing.ICA(n_components=15, random_state=97, max_iter=800)\n",
    "    ica.fit(raw)\n",
    "    raw = ica.apply(raw)\n",
    "\n",
    "    # Extract events and epochs\n",
    "    events, _ = mne.events_from_annotations(raw)\n",
    "    epochs = mne.Epochs(raw, events, event_id=event_ids, tmin=0.5, tmax=4.0, baseline=(0.5, 1.0), preload=True)\n",
    "\n",
    "    all_features.append(epochs.get_data())  # Shape: (n_epochs, n_channels, n_times)\n",
    "    all_labels.append(epochs.events[:, -1])  # Event IDs\n",
    "\n",
    "# Combine all subjects' data\n",
    "features = np.concatenate(all_features, axis=0)\n",
    "labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Normalize features (Z-score normalization)\n",
    "normalized_features = (features - np.mean(features, axis=0)) / np.std(features, axis=0)\n",
    "\n",
    "# One-hot encode labels\n",
    "labels = to_categorical(labels - 7)\n",
    "\n",
    "# Reshape features for CNN input\n",
    "normalized_features = normalized_features[..., np.newaxis]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    normalized_features, labels, test_size=0.15, random_state=42, stratify=labels.argmax(axis=1))\n",
    "\n",
    "# ------------------- Define the EEGNet Model -------------------\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(1, 64), padding='same', activation='relu',\n",
    "                 kernel_regularizer=l2(0.01), input_shape=(22, X_train.shape[2], 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(DepthwiseConv2D(kernel_size=(22, 1), depth_multiplier=2, activation='relu', use_bias=False,\n",
    "                          kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(SeparableConv2D(32, kernel_size=(1, 16), activation='relu', use_bias=False, padding='same',\n",
    "                          kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ------------------- Train the Model -------------------\n",
    "\n",
    "# Define callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32,\n",
    "                    validation_split=0.15, callbacks=[reduce_lr, early_stopping], verbose=1)\n",
    "\n",
    "# ------------------- Evaluate the Model -------------------\n",
    "\n",
    "# Evaluate model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Set Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Generate predictions and evaluation metrics\n",
    "y_test_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_test_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_true, y_test_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_true, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# ------------------- Cross-Validation -------------------\n",
    "\n",
    "# StratifiedKFold for maintaining class distribution\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_no = 1\n",
    "input_shape = (normalized_features.shape[1], normalized_features.shape[2], 1)\n",
    "num_classes = labels_categorical.shape[1]\n",
    "\n",
    "accuracy_per_fold = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for train_index, val_index in kfold.split(normalized_features, labels):\n",
    "    # Split data\n",
    "    X_train, X_val = normalized_features[train_index], normalized_features[val_index]\n",
    "    y_train, y_val = labels_categorical[train_index], labels_categorical[val_index]\n",
    "\n",
    "    # Initialize model\n",
    "    model = create_model(input_shape, num_classes)  # Use the create_model function from the earlier code\n",
    "\n",
    "    # Define callbacks\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"\\nTraining fold {fold_no}...\")\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val),\n",
    "              callbacks=[reduce_lr, early_stopping], verbose=1)\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    accuracy_per_fold.append(val_accuracy)\n",
    "    print(f\"Fold {fold_no} Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Predict and calculate confusion matrix\n",
    "    y_val_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "    y_val_true = np.argmax(y_val, axis=1)\n",
    "    confusion_matrices.append(confusion_matrix(y_val_true, y_val_pred))\n",
    "\n",
    "    # Increment fold number\n",
    "    fold_no += 1\n",
    "\n",
    "# ------------------- Results Summary -------------------\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "for i, acc in enumerate(accuracy_per_fold):\n",
    "    print(f\"Fold {i + 1}: Accuracy = {acc * 100:.2f}%\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracy_per_fold) * 100:.2f}%\")\n",
    "print(f\"Standard Deviation: {np.std(accuracy_per_fold) * 100:.2f}%\")\n",
    "\n",
    "# Print confusion matrices\n",
    "for i, cm in enumerate(confusion_matrices):\n",
    "    print(f\"\\nConfusion Matrix for Fold {i + 1}:\\n{cm}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
