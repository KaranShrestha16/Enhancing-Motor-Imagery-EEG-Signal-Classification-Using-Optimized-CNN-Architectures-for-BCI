{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing A01...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 14.1s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A02...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 16.6s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A03...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 21.6s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A05...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686119  =      0.000 ...  2744.476 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 16.3s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A06...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 678979  =      0.000 ...  2715.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 19.1s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A07...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 12.4s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A08...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675269  =      0.000 ...  2701.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 18.1s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Processing A09...\n",
      "Extracting EDF parameters from C:\\Users\\karan\\Downloads\\EEG Data\\Data\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 20.9s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 876 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.5185 - loss: 2.1573 - val_accuracy: 0.5420 - val_loss: 1.4979 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 93ms/step - accuracy: 0.5788 - loss: 1.3374 - val_accuracy: 0.5884 - val_loss: 1.1723 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 86ms/step - accuracy: 0.6645 - loss: 1.0604 - val_accuracy: 0.6837 - val_loss: 1.0119 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.7361 - loss: 0.9659 - val_accuracy: 0.8107 - val_loss: 0.8851 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.7909 - loss: 0.9230 - val_accuracy: 0.8254 - val_loss: 0.8537 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8001 - loss: 0.9233 - val_accuracy: 0.8662 - val_loss: 0.8413 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.8494 - loss: 0.8727 - val_accuracy: 0.9070 - val_loss: 0.8119 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m 40/157\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.8289 - loss: 0.8946"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, SeparableConv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- Data Loading and Preprocessing ----------------\n",
    "\n",
    "base_path = r'C:\\\\Users\\\\karan\\\\Downloads\\\\EEG Data\\\\Data'\n",
    "subjects = [f'A0{i}' for i in range(1, 10) if i != 4]\n",
    "event_ids = [7, 8, 9, 10]  # Event IDs for motor imagery tasks\n",
    "\n",
    "all_features, all_labels = [], []\n",
    "\n",
    "for subject in subjects:\n",
    "    file_path = f'{base_path}\\\\{subject}T.gdf'\n",
    "    print(f\"Processing {subject}...\")\n",
    "\n",
    "    raw = mne.io.read_raw_gdf(file_path, preload=True)\n",
    "    raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    raw.set_eeg_reference()\n",
    "    raw.filter(8., 30., fir_design='firwin', verbose=False)\n",
    "\n",
    "    ica = mne.preprocessing.ICA(n_components=15, random_state=97, max_iter=800)\n",
    "    ica.fit(raw)\n",
    "    raw = ica.apply(raw)\n",
    "\n",
    "    events, _ = mne.events_from_annotations(raw)\n",
    "    epochs = mne.Epochs(raw, events, event_id=event_ids, tmin=0.5, tmax=4.0, baseline=(0.5, 1.0), preload=True)\n",
    "\n",
    "    all_features.append(epochs.get_data())\n",
    "    all_labels.append(epochs.events[:, -1])\n",
    "\n",
    "features = np.concatenate(all_features, axis=0)\n",
    "labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# ---------------- Data Preparation ----------------\n",
    "\n",
    "# Map labels to binary classification: Tongue = 1, Non-Tongue = 0\n",
    "binary_labels = np.where(labels == 10, 1, 0)  # Event ID for Tongue is 10\n",
    "tongue_features = features[binary_labels == 1]\n",
    "non_tongue_features = features[binary_labels == 0]\n",
    "\n",
    "# Oversample Tongue trials to balance the dataset\n",
    "n_tongue = len(tongue_features)\n",
    "n_non_tongue = len(non_tongue_features)\n",
    "oversampled_tongue_features = np.tile(tongue_features, (n_non_tongue // n_tongue, 1, 1))\n",
    "remainder = n_non_tongue % n_tongue\n",
    "if remainder > 0:\n",
    "    oversampled_tongue_features = np.concatenate([oversampled_tongue_features, tongue_features[:remainder]], axis=0)\n",
    "\n",
    "# Combine the balanced dataset\n",
    "balanced_features = np.concatenate([oversampled_tongue_features, non_tongue_features], axis=0)\n",
    "balanced_labels = np.concatenate([np.ones(len(oversampled_tongue_features)), np.zeros(n_non_tongue)], axis=0)\n",
    "\n",
    "# Normalize the features (Z-score normalization)\n",
    "balanced_features = (balanced_features - np.mean(balanced_features, axis=0)) / np.std(balanced_features, axis=0)\n",
    "\n",
    "# Add Gaussian noise for data augmentation\n",
    "noise_factor = 0.05\n",
    "augmented_features = balanced_features + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=balanced_features.shape)\n",
    "augmented_features = np.clip(augmented_features, -1.0, 1.0)\n",
    "\n",
    "# Combine original and augmented datasets\n",
    "final_features = np.concatenate((balanced_features, augmented_features))\n",
    "final_labels = np.concatenate((balanced_labels, balanced_labels))\n",
    "final_features, final_labels = shuffle(final_features, final_labels, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_features, final_labels, test_size=0.15, random_state=42)\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "# ---------------- Build the Model ----------------\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(1, 64), padding='same', input_shape=(22, X_train.shape[2], 1),\n",
    "                 activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(DepthwiseConv2D(kernel_size=(22, 1), depth_multiplier=2, use_bias=False, activation='relu',\n",
    "                          depthwise_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(SeparableConv2D(16, kernel_size=(1, 16), use_bias=False, padding='same', activation='relu',\n",
    "                          depthwise_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(1, 4)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ---------------- Train the Model ----------------\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.15,\n",
    "                    callbacks=[reduce_lr, early_stopping], verbose=1)\n",
    "\n",
    "# ---------------- Evaluate the Model ----------------\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ---------------- Plot Confusion Matrix ----------------\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    conf_matrix,\n",
    "    class_names=['Non-Tongue', 'Tongue'],\n",
    "    title=\"Enhanced EEGNet: Tongue vs Non-Tongue Model - Confusion Matrix\"\n",
    ")\n",
    "\n",
    "# ---------------- Plot Training and Validation Trends ----------------\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Enhanced EEGNet: Tongue vs Non-Tongue Model - Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Enhanced EEGNet: Tongue vs Non-Tongue Model - Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ---------------- Plot ROC Curve ----------------\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.title('Enhanced EEGNet: Tongue vs Non-Tongue Model - ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.5392 - loss: 2.1494 - val_accuracy: 0.5510 - val_loss: 1.4949 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - accuracy: 0.6537 - loss: 1.3225 - val_accuracy: 0.5964 - val_loss: 1.3588 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - accuracy: 0.6983 - loss: 1.0833 - val_accuracy: 0.7279 - val_loss: 1.0017 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.7548 - loss: 0.9510 - val_accuracy: 0.7846 - val_loss: 0.9184 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7909 - loss: 0.9287 - val_accuracy: 0.8209 - val_loss: 0.8788 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 76ms/step - accuracy: 0.8212 - loss: 0.8843 - val_accuracy: 0.8605 - val_loss: 0.8369 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.8497 - loss: 0.8485 - val_accuracy: 0.8832 - val_loss: 0.7764 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - accuracy: 0.8647 - loss: 0.8010 - val_accuracy: 0.8617 - val_loss: 0.7924 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - accuracy: 0.8537 - loss: 0.8657 - val_accuracy: 0.9116 - val_loss: 0.7546 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.8837 - loss: 0.7947 - val_accuracy: 0.9082 - val_loss: 0.7752 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.8861 - loss: 0.8082 - val_accuracy: 0.9138 - val_loss: 0.7528 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.8617 - loss: 0.8869 - val_accuracy: 0.9252 - val_loss: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.8957 - loss: 0.8143 - val_accuracy: 0.9286 - val_loss: 0.7273 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.9065 - loss: 0.7591 - val_accuracy: 0.9252 - val_loss: 0.7253 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.8830 - loss: 0.8176 - val_accuracy: 0.9569 - val_loss: 0.6875 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9036 - loss: 0.7775 - val_accuracy: 0.9399 - val_loss: 0.7114 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9042 - loss: 0.7940 - val_accuracy: 0.9354 - val_loss: 0.7130 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9037 - loss: 0.7843 - val_accuracy: 0.9184 - val_loss: 0.7521 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.8980 - loss: 0.7986 - val_accuracy: 0.9399 - val_loss: 0.7419 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8819 - loss: 0.8911\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.8819 - loss: 0.8913 - val_accuracy: 0.9172 - val_loss: 0.8136 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.9180 - loss: 0.8124 - val_accuracy: 0.9546 - val_loss: 0.6409 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9309 - loss: 0.6720 - val_accuracy: 0.9728 - val_loss: 0.5466 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9310 - loss: 0.6049 - val_accuracy: 0.9694 - val_loss: 0.4868 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9500 - loss: 0.5181 - val_accuracy: 0.9683 - val_loss: 0.4680 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9444 - loss: 0.5082 - val_accuracy: 0.9660 - val_loss: 0.4407 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9399 - loss: 0.5081 - val_accuracy: 0.9751 - val_loss: 0.4335 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9474 - loss: 0.4752 - val_accuracy: 0.9751 - val_loss: 0.4188 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9460 - loss: 0.4715 - val_accuracy: 0.9739 - val_loss: 0.4293 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9394 - loss: 0.4988 - val_accuracy: 0.9728 - val_loss: 0.4091 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9465 - loss: 0.4759 - val_accuracy: 0.9705 - val_loss: 0.4315 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9460 - loss: 0.4726 - val_accuracy: 0.9705 - val_loss: 0.4212 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9359 - loss: 0.5031 - val_accuracy: 0.9728 - val_loss: 0.4373 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9333 - loss: 0.5134 - val_accuracy: 0.9717 - val_loss: 0.4386 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9497 - loss: 0.4798\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9496 - loss: 0.4799 - val_accuracy: 0.9819 - val_loss: 0.4269 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9480 - loss: 0.4769 - val_accuracy: 0.9762 - val_loss: 0.4042 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9672 - loss: 0.4162 - val_accuracy: 0.9853 - val_loss: 0.3683 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.9677 - loss: 0.3901 - val_accuracy: 0.9819 - val_loss: 0.3484 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - accuracy: 0.9686 - loss: 0.3705 - val_accuracy: 0.9864 - val_loss: 0.3212 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - accuracy: 0.9648 - loss: 0.3595 - val_accuracy: 0.9830 - val_loss: 0.3165 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - accuracy: 0.9711 - loss: 0.3450 - val_accuracy: 0.9841 - val_loss: 0.2992 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - accuracy: 0.9694 - loss: 0.3233 - val_accuracy: 0.9796 - val_loss: 0.2910 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 76ms/step - accuracy: 0.9759 - loss: 0.3100 - val_accuracy: 0.9751 - val_loss: 0.2908 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.9731 - loss: 0.2993 - val_accuracy: 0.9796 - val_loss: 0.2808 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.9649 - loss: 0.3224 - val_accuracy: 0.9864 - val_loss: 0.2798 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.9654 - loss: 0.3154 - val_accuracy: 0.9762 - val_loss: 0.2911 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9751 - loss: 0.2999 - val_accuracy: 0.9841 - val_loss: 0.2679 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.9740 - loss: 0.2861 - val_accuracy: 0.9853 - val_loss: 0.2629 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.9725 - loss: 0.2919 - val_accuracy: 0.9819 - val_loss: 0.2601 - learning_rate: 2.5000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.9691 - loss: 0.2895 - val_accuracy: 0.9807 - val_loss: 0.2620 - learning_rate: 2.5000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.9758 - loss: 0.2757 - val_accuracy: 0.9841 - val_loss: 0.2472 - learning_rate: 2.5000e-04\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Test Accuracy: 97.78%\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "Confusion Matrix:\n",
      " [[500  22]\n",
      " [  1 514]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98       522\n",
      "         1.0       0.96      1.00      0.98       515\n",
      "\n",
      "    accuracy                           0.98      1037\n",
      "   macro avg       0.98      0.98      0.98      1037\n",
      "weighted avg       0.98      0.98      0.98      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, SeparableConv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# ---------------- Data Preparation for tongue vs. Non-tongue Classification ----------------\n",
    "\n",
    "# Map labels to binary classification: tongue = 1, Non-tongue = 0\n",
    "binary_labels = np.where(labels == 10, 1, 0)  # Event ID for tongue is 10\n",
    "\n",
    "# Separate tongue and Non-tongue data\n",
    "tongue_features = features[binary_labels == 1]\n",
    "non_tongue_features = features[binary_labels == 0]\n",
    "\n",
    "# Oversample tongue trials to balance the dataset\n",
    "n_tongue = len(tongue_features)\n",
    "n_non_tongue = len(non_tongue_features)\n",
    "oversampled_tongue_features = np.tile(tongue_features, (n_non_tongue // n_tongue, 1, 1))\n",
    "remainder = n_non_tongue % n_tongue\n",
    "if remainder > 0:\n",
    "    oversampled_tongue_features = np.concatenate([oversampled_tongue_features, tongue_features[:remainder]], axis=0)\n",
    "\n",
    "# Combine and shuffle the balanced dataset\n",
    "balanced_features = np.concatenate([oversampled_tongue_features, non_tongue_features], axis=0)\n",
    "balanced_labels = np.concatenate([np.ones(len(oversampled_tongue_features)), np.zeros(n_non_tongue)], axis=0)\n",
    "\n",
    "# Normalize the features (Z-score normalization)\n",
    "balanced_features = (balanced_features - np.mean(balanced_features, axis=0)) / np.std(balanced_features, axis=0)\n",
    "\n",
    "# Apply Gaussian noise for data augmentation\n",
    "noise_factor = 0.05\n",
    "augmented_features = balanced_features + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=balanced_features.shape)\n",
    "augmented_features = np.clip(augmented_features, -1.0, 1.0)  # Ensure valid range for EEG signals\n",
    "\n",
    "# Combine original and augmented data\n",
    "final_features = np.concatenate((balanced_features, augmented_features))\n",
    "final_labels = np.concatenate((balanced_labels, balanced_labels))\n",
    "\n",
    "# Shuffle the final dataset\n",
    "final_features, final_labels = shuffle(final_features, final_labels, random_state=42)\n",
    "\n",
    "# Split into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_features, final_labels, test_size=0.15, random_state=42)\n",
    "\n",
    "# Reshape data for CNN input\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "# ---------------- Build the EEGNet Model ----------------\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Temporal Convolution Block\n",
    "model.add(Conv2D(8, kernel_size=(1, 64), padding='same', input_shape=(22, X_train.shape[2], 1),\n",
    "                 activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(DepthwiseConv2D(kernel_size=(22, 1), depth_multiplier=2, use_bias=False, activation='relu',\n",
    "                          depthwise_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))  # Increased dropout for regularization\n",
    "\n",
    "# Spatial Convolution Block\n",
    "model.add(SeparableConv2D(16, kernel_size=(1, 16), use_bias=False, padding='same', activation='relu',\n",
    "                          depthwise_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(1, 4)))\n",
    "model.add(Dropout(0.4))  # Increased dropout\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "# Compile the Model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ---------------- Training the Model ----------------\n",
    "\n",
    "# Callbacks for learning rate adjustment and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ---------------- Evaluate the Model ----------------\n",
    "\n",
    "# Test accuracy\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)  # Default threshold 0.5\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# ---------------- Stratified K-Fold Cross-Validation ----------------\n",
    "\n",
    "n_splits = 5  # Number of folds\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics storage\n",
    "fold_accuracies = []\n",
    "fold_losses = []\n",
    "fold_roc_aucs = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf.split(final_features, final_labels):\n",
    "    print(f\"\\nTraining Fold {fold}...\")\n",
    "\n",
    "    # Split data into training and testing sets for the fold\n",
    "    X_train_fold = final_features[train_index][..., np.newaxis]\n",
    "    X_test_fold = final_features[test_index][..., np.newaxis]\n",
    "    y_train_fold = final_labels[train_index]\n",
    "    y_test_fold = final_labels[test_index]\n",
    "\n",
    "    # Build the model for each fold\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, kernel_size=(1, 64), padding='same', input_shape=(22, X_train_fold.shape[2], 1),\n",
    "                     activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(DepthwiseConv2D(kernel_size=(22, 1), depth_multiplier=2, use_bias=False, activation='relu',\n",
    "                              depthwise_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(SeparableConv2D(16, kernel_size=(1, 16), use_bias=False, padding='same', activation='relu',\n",
    "                              depthwise_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(1, 4)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.15,\n",
    "        callbacks=[reduce_lr, early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_fold, y_test_fold, verbose=0)\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "    fold_losses.append(test_loss)\n",
    "    print(f\"Fold {fold} Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "    print(f\"Fold {fold} Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Predictions and probabilities\n",
    "    y_pred_probs = model.predict(X_test_fold)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics for the fold\n",
    "    roc_auc = roc_auc_score(y_test_fold, y_pred_probs)\n",
    "    fold_roc_aucs.append(roc_auc)\n",
    "    print(f\"Fold {fold} ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test_fold, y_pred, average='binary')\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    print(f\"Fold {fold} Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# ---------------- Cross-Validation Results ----------------\n",
    "\n",
    "# Compute overall averages and standard deviations\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "average_loss = np.mean(fold_losses)\n",
    "std_loss = np.std(fold_losses)\n",
    "average_roc_auc = np.mean(fold_roc_aucs)\n",
    "std_roc_auc = np.std(fold_roc_aucs)\n",
    "average_precision = np.mean(precision_list)\n",
    "average_recall = np.mean(recall_list)\n",
    "average_f1 = np.mean(f1_list)\n",
    "\n",
    "# Print overall cross-validation results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {average_accuracy * 100:.2f}%\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy * 100:.2f}%\")\n",
    "print(f\"Average Loss: {average_loss:.4f}\")\n",
    "print(f\"Standard Deviation of Loss: {std_loss:.4f}\")\n",
    "print(f\"Average ROC-AUC: {average_roc_auc:.4f}\")\n",
    "print(f\"Standard Deviation of ROC-AUC: {std_roc_auc:.4f}\")\n",
    "print(f\"Average Precision: {average_precision:.4f}\")\n",
    "print(f\"Average Recall: {average_recall:.4f}\")\n",
    "print(f\"Average F1-Score: {average_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
